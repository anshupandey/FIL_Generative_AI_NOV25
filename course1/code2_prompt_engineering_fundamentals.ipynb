{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/prompt_engineering/blob/main/code1_prompt_engineering_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr0_RIhOerKl"
      },
      "source": [
        "# Prompt Engineering with OpenAI LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz0bz_xlerKp"
      },
      "source": [
        "Notebook available at: https://github.com/Bluedata-Consulting/GAAI-B4-Azure/blob/main/SELFLEARNING/code3_prompt_engineering_fundamentals.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hCfQdmcomTyL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from openai import AzureOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "25-Pe4z4mzMF"
      },
      "outputs": [],
      "source": [
        "client = AzureOpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqV1gcAmq1mz",
        "outputId": "27aaa8aa-32ee-47f4-bba7-afd1a97cbff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantum computing uses the principles of quantum mechanics to process information in ways that classical computers can't, by utilizing qubits instead of traditional bits. This allows quantum computers to solve complex problems much faster, potentially revolutionizing fields like cryptography and drug discovery.\n"
          ]
        }
      ],
      "source": [
        "response = client.chat.completions.create(model='gpt-4o-mini',\n",
        "                               messages=[{'role':'user','content':'explain quantum computing in simple terms, 2 lines'}])\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU1h2JudrWBZ",
        "outputId": "4ae3ed7e-ec2b-41ce-9478-d97793268653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"id\": \"chatcmpl-CdC2pl3uepSoUCVKLpFMNWDRUdAMj\",\n",
            "  \"choices\": [\n",
            "    {\n",
            "      \"finish_reason\": \"stop\",\n",
            "      \"index\": 0,\n",
            "      \"logprobs\": null,\n",
            "      \"message\": {\n",
            "        \"content\": \"Quantum computing uses the principles of quantum mechanics to process information in ways that classical computers can't, by utilizing qubits instead of traditional bits. This allows quantum computers to solve complex problems much faster, potentially revolutionizing fields like cryptography and drug discovery.\",\n",
            "        \"refusal\": null,\n",
            "        \"role\": \"assistant\",\n",
            "        \"annotations\": []\n",
            "      },\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"protected_material_text\": {\n",
            "          \"filtered\": false,\n",
            "          \"detected\": false\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ],\n",
            "  \"created\": 1763457127,\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"chat.completion\",\n",
            "  \"system_fingerprint\": \"fp_efad92c60b\",\n",
            "  \"usage\": {\n",
            "    \"completion_tokens\": 50,\n",
            "    \"prompt_tokens\": 18,\n",
            "    \"total_tokens\": 68,\n",
            "    \"completion_tokens_details\": {\n",
            "      \"accepted_prediction_tokens\": 0,\n",
            "      \"audio_tokens\": 0,\n",
            "      \"reasoning_tokens\": 0,\n",
            "      \"rejected_prediction_tokens\": 0\n",
            "    },\n",
            "    \"prompt_tokens_details\": {\n",
            "      \"audio_tokens\": 0,\n",
            "      \"cached_tokens\": 0\n",
            "    }\n",
            "  },\n",
            "  \"prompt_filter_results\": [\n",
            "    {\n",
            "      \"prompt_index\": 0,\n",
            "      \"content_filter_results\": {\n",
            "        \"hate\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"jailbreak\": {\n",
            "          \"filtered\": false,\n",
            "          \"detected\": false\n",
            "        },\n",
            "        \"self_harm\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"sexual\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        },\n",
            "        \"violence\": {\n",
            "          \"filtered\": false,\n",
            "          \"severity\": \"safe\"\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response.to_json(indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCSXh37_rV29"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTy9qlaNbhw1",
        "outputId": "41ce1be7-77e5-4992-8636-af09f4f6d5b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To output all files in a directory using Python, you can use the `os` module or the `pathlib` module. Below are examples of how to do this with both methods.\n",
            "\n",
            "### Using the `os` module\n",
            "\n",
            "You can use the `os.listdir()` function to list all entries in a directory, and then use `os.path.isfile()` to filter out files. Here's an example:\n",
            "\n",
            "```python\n",
            "import os\n",
            "\n",
            "# Specify the directory\n",
            "directory = '/path/to/directory'\n",
            "\n",
            "# List all files in the directory\n",
            "for filename in os.listdir(directory):\n",
            "    file_path = os.path.join(directory, filename)\n",
            "    if os.path.isfile(file_path):\n",
            "        print(filename)\n",
            "```\n",
            "\n",
            "### Using the `pathlib` module\n",
            "\n",
            "The `pathlib` module provides an object-oriented approach to handling filesystem paths. Here's how to use it to list all files in a directory:\n",
            "\n",
            "```python\n",
            "from pathlib import Path\n",
            "\n",
            "# Specify the directory\n",
            "directory = Path('/path/to/directory')\n",
            "\n",
            "# List all files in the directory\n",
            "for file in directory.iterdir():\n",
            "    if file.is_file():\n",
            "        print(file.name)\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "- Replace `'/path/to/directory'` with the path of the directory you want to read.\n",
            "- Both snippets will print the names of all files (not directories) in the specified directory.\n",
            "\n",
            "### Note:\n",
            "Make sure to have permission to access the directory you're querying, or you might encounter permissions errors.\n"
          ]
        }
      ],
      "source": [
        "result = client.chat.completions.create(\n",
        "    model='gpt-4o-mini',  # e.g. gpt-35-instant\n",
        "    max_tokens=500,\n",
        "    temperature=0.9,\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"How do I output all files in a directory using Python?\",\n",
        "        },\n",
        "    ],\n",
        ")\n",
        "print(result.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0WAxkVWZ7LRi"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(prompt,model='gpt-4o-mini',temperature=0):\n",
        "  messages = [{\"role\":\"system\",\"content\":\"you are a helpful assistant\"},\n",
        "    {\"role\":\"user\",\"content\":prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=temperature,\n",
        "      #top_p=0.99\n",
        "  )\n",
        "  return response.choices[0].message.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLgNfQbz7xpQ",
        "outputId": "0dfa0dec-defa-4a51-dcf8-bd2958ccde47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Here is a simple Python code snippet that prints \"Hello World\":\n",
            "\n",
            "```python\n",
            "print(\"Hello World\")\n",
            "```\n",
            "\n",
            "You can run this code in any Python environment, such as a Python interpreter, a script file, or an online Python compiler.\n"
          ]
        }
      ],
      "source": [
        "response = generate_response(\"Write a python code to print 'Hello World'\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZcaHAuU94x0"
      },
      "source": [
        "## Experimenting with different values of temperature:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMwThtKC94x0",
        "outputId": "ae5de8d8-a8de-4c75-97f6-f12e19408944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    response = generate_response(prompt=\"complete the following sentence: \\n\\n 'I am visiting Manila, its is a city of '\",\n",
        "                                 temperature=0)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfGFmz4K94x0",
        "outputId": "76282132-df71-40a7-dec8-2de159155e73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "At Temperature: 0\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "************************************************************\n",
            "At Temperature: 0.4\n",
            "'I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.'\n",
            "************************************************************\n",
            "At Temperature: 0.8\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and bustling energy.\"\n",
            "************************************************************\n",
            "At Temperature: 1.2\n",
            "\"I am visiting Manila, it is a city of rich history, vibrant culture, and bustling markets.\"\n",
            "************************************************************\n",
            "At Temperature: 1.5\n",
            "\"I am visiting Manila, it is a city of vibrant culture, rich history, and lively streets filled with both traditional and modern influences.\"\n",
            "************************************************************\n",
            "At Temperature: 1.8\n",
            "'I am visiting Manila, it is a city of rich history and vibrant culture, recognizable by the classic architecture, bustling markets, and warm hospitality of its people.'\n",
            "************************************************************\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m tvalues \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.4\u001b[39m,\u001b[38;5;241m0.8\u001b[39m,\u001b[38;5;241m1.2\u001b[39m,\u001b[38;5;241m1.5\u001b[39m,\u001b[38;5;241m1.8\u001b[39m,\u001b[38;5;241m2.0\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tvalues)):\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomplete the following sentence: \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mI am visiting Manila, its is a city of \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAt Temperature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtvalues[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
            "Cell \u001b[1;32mIn[15], line 5\u001b[0m, in \u001b[0;36mgenerate_response\u001b[1;34m(prompt, model, temperature)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_response\u001b[39m(prompt,model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m'\u001b[39m,temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      3\u001b[0m   messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou are a helpful assistant\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      4\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m:prompt}]\n\u001b[1;32m----> 5\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m#top_p=0.99\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_utils\\_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1189\u001b[0m, in \u001b[0;36mCompletions.create\u001b[1;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m   1142\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m not_given,\n\u001b[0;32m   1187\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m   1188\u001b[0m     validate_response_format(response_format)\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1192\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m   1193\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1194\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1195\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1196\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1197\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1198\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1199\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1200\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1201\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1202\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1208\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1209\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_retention\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1258\u001b[0m     )\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\openai\\_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39msend(\n\u001b[0;32m    983\u001b[0m         request,\n\u001b[0;32m    984\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream_response_body(request\u001b[38;5;241m=\u001b[39mrequest),\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    986\u001b[0m     )\n\u001b[0;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1011\u001b[0m     )\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpx\\_transports\\default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    248\u001b[0m )\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[0;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[0;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    259\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    213\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, Iterable)\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    192\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\connection.py:101\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:143\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[1;32m--> 143\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:113\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m    107\u001b[0m     (\n\u001b[0;32m    108\u001b[0m         http_version,\n\u001b[0;32m    109\u001b[0m         status,\n\u001b[0;32m    110\u001b[0m         reason_phrase,\n\u001b[0;32m    111\u001b[0m         headers,\n\u001b[0;32m    112\u001b[0m         trailing_data,\n\u001b[1;32m--> 113\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_receive_response_headers(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    114\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    115\u001b[0m         http_version,\n\u001b[0;32m    116\u001b[0m         status,\n\u001b[0;32m    117\u001b[0m         reason_phrase,\n\u001b[0;32m    118\u001b[0m         headers,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[0;32m    121\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:186\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    183\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 186\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_sync\\http11.py:224\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    221\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[1;32m--> 224\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[0;32m    235\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
            "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[1;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[1;32m--> 126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\ssl.py:1259\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[1;34m(self, buflen, flags)\u001b[0m\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1258\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
            "File \u001b[1;32mc:\\ProgramData\\anaconda3\\lib\\ssl.py:1132\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "tvalues = [0,0.4,0.8,1.2,1.5,1.8,2.0]\n",
        "for i in range(len(tvalues)):\n",
        "    response = generate_response(prompt=\"complete the following sentence: \\n\\n 'I am visiting Manila, its is a city of '\",\n",
        "                                 temperature=tvalues[i])\n",
        "    print(f\"At Temperature: {tvalues[i]}\")\n",
        "    print(response)\n",
        "    print(\"***\"*20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ml6B5pyNerK0",
        "outputId": "abc0cde6-bc20-431e-ac2b-ccb879b9065b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic arts scene.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic arts scene.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historical landmarks, and dynamic economy.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic arts scene.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic economy.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic economy.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic arts scene.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic economy.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic economy.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse communities, historic landmarks, and dynamic economy.\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(generate_response(\"Complete the sentence: Manila is a city of \",temperature=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "BbkSLBLLerK1",
        "outputId": "a35a10b7-3194-4f40-c6fa-2722096db1a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Manila is a city of rich history, vibrant culture, and bustling urban life, serving as the capital of the Philippines and a hub for commerce, education, and tourism in Southeast Asia.\n",
            "Manila is a city of rich history, vibrant culture, and bustling urban life, serving as the capital of the Philippines and a hub for commerce, education, and tourism in Southeast Asia.\n",
            "Manila is a city of rich history and vibrant culture, known for its bustling streets, diverse population, and significant landmarks that reflect its colonial past and modern development.\n",
            "Manila is a city of rich history, vibrant culture, and bustling urban life, serving as the capital of the Philippines.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, serving as the capital of the Philippines and a key hub for commerce, education, and tourism in the region.\n",
            "Manila is a city of rich history and vibrant culture, known for its bustling streets, diverse population, and significant landmarks that reflect its Spanish colonial past and modern urban development.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its diverse neighborhoods, historic landmarks, and dynamic street life.\n",
            "Manila is a city of rich history and vibrant culture, where stunning colonial architecture coexists with modern skyscrapers, creating a unique blend of old and new.\n",
            "Manila is a city of rich history, vibrant culture, and bustling modernity, where colonial heritage meets contemporary influences along its intricate streets and rivers.\n",
            "Manila is a city of rich history and vibrant culture, serving as the capital of the Philippines and a hub for arts, commerce, and diversity.\n",
            "Manila is a city of vibrant culture, rich history, and bustling urban life, known for its attractive colonial architecture, lively markets, and outrageous day and nighttime activity along the scenic waterfront.\n"
          ]
        }
      ],
      "source": [
        "for i in [0,0.2,0.4,0.6,0.8,1.0,1.25,1.5,1.7,1.8,1.9]:\n",
        "    print(generate_response(\"Complete the sentence: Manila is a city of \",temperature=i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjXhLCm6erK2"
      },
      "source": [
        "## Guildelines for Prompting\n",
        "1. Persona\n",
        "2. Instructions\n",
        "3. Context\n",
        "4. Constraint\n",
        "5. Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5qMlyXierK3",
        "outputId": "230a75ad-6464-42b9-a2a5-0bb6868e471d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Below is a Python code snippet that generates the Fibonacci series up to a specified number of terms:\n",
            "\n",
            "```python\n",
            "def fibonacci_series(n):\n",
            "    fib_series = []\n",
            "    a, b = 0, 1\n",
            "    for _ in range(n):\n",
            "        fib_series.append(a)\n",
            "        a, b = b, a + b\n",
            "    return fib_series\n",
            "\n",
            "# Specify the number of terms you want in the Fibonacci series\n",
            "num_terms = int(input(\"Enter the number of terms in the Fibonacci series: \"))\n",
            "result = fibonacci_series(num_terms)\n",
            "print(\"Fibonacci series:\", result)\n",
            "```\n",
            "\n",
            "### How it works:\n",
            "1. The function `fibonacci_series(n)` generates the Fibonacci series up to `n` terms.\n",
            "2. It initializes the first two Fibonacci numbers, `a` (0) and `b` (1).\n",
            "3. It uses a loop to append the current Fibonacci number (`a`) to the list and then updates `a` and `b` to the next two Fibonacci numbers.\n",
            "4. Finally, it returns the list containing the Fibonacci series.\n",
            "\n",
            "You can run this code in a Python environment, and it will prompt you to enter the number of terms you want in the Fibonacci series.\n"
          ]
        }
      ],
      "source": [
        "# Persona and Instruction\n",
        "\n",
        "prompt = \"\"\"\n",
        "Write a python code to generate fibonnacci series.\n",
        "\"\"\"\n",
        "\n",
        "out = generate_response(prompt)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaEtcLiRerK4",
        "outputId": "015c2750-88b2-46f1-b37f-fbee31f5d423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Certainly! Below is a Python code snippet that generates the Fibonacci series. The code is designed to be clean, secure, and readable. It includes a function that generates the Fibonacci series up to a specified number of terms.\n",
            "\n",
            "```python\n",
            "def fibonacci_series(n):\n",
            "    \"\"\"\n",
            "    Generate a Fibonacci series up to n terms.\n",
            "\n",
            "    :param n: The number of terms in the Fibonacci series to generate.\n",
            "    :return: A list containing the Fibonacci series.\n",
            "    \"\"\"\n",
            "    if n <= 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return [0]\n",
            "    elif n == 2:\n",
            "        return [0, 1]\n",
            "\n",
            "    series = [0, 1]\n",
            "    for i in range(2, n):\n",
            "        next_value = series[-1] + series[-2]\n",
            "        series.append(next_value)\n",
            "\n",
            "    return series\n",
            "\n",
            "# Example usage\n",
            "if __name__ == \"__main__\":\n",
            "    num_terms = 10  # Specify the number of terms you want\n",
            "    fib_series = fibonacci_series(num_terms)\n",
            "    print(f\"Fibonacci series up to {num_terms} terms: {fib_series}\")\n",
            "```\n",
            "\n",
            "### Explanation:\n",
            "1. **Function Definition**: The `fibonacci_series` function takes an integer `n` as input, which specifies how many terms of the Fibonacci series to generate.\n",
            "2. **Input Validation**: The function checks if `n` is less than or equal to 0 and returns an empty list in that case. It also handles cases for `n` equal to 1 and 2 separately.\n",
            "3. **Series Generation**: For `n` greater than 2, it initializes the series with the first two Fibonacci numbers (0 and 1) and then uses a loop to calculate the subsequent numbers by summing the last two numbers in the series.\n",
            "4. **Example Usage**: The code includes a main block that demonstrates how to use the function and prints the generated Fibonacci series.\n",
            "\n",
            "You can run this code in any Python environment, and it will output the Fibonacci series for the specified number of terms.\n"
          ]
        }
      ],
      "source": [
        "# Persona and Instruction\n",
        "\n",
        "prompt = \"\"\" You are an experienced senior software developer who writes clean, secure, readable codes using python.\n",
        "Write a python code to generate fibonnacci series.\n",
        "\"\"\"\n",
        "\n",
        "out = generate_response(prompt)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOtBpiwaerK4",
        "outputId": "f9ac36c3-6fff-4b53-86aa-5f5b5073544d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "def fibonacci_series(n):\n",
            "    if n <= 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return [0]\n",
            "    elif n == 2:\n",
            "        return [0, 1]\n",
            "    \n",
            "    series = [0, 1]\n",
            "    for i in range(2, n):\n",
            "        next_value = series[-1] + series[-2]\n",
            "        series.append(next_value)\n",
            "    \n",
            "    return series\n",
            "\n",
            "# Example usage:\n",
            "# print(fibonacci_series(10))\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Persona, Instruction and constraint\n",
        "\n",
        "prompt = \"\"\" You are an experienced senior software developer who writes clean, secure, readable codes using python.\n",
        "Write a python code to generate fibonnacci series.\n",
        "\n",
        "Only provide python code, no explaantion outside function block.\n",
        "\"\"\"\n",
        "\n",
        "out = generate_response(prompt)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02DEhtLX1YAc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJDRwll01Uff"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZXxx-2_erK5"
      },
      "source": [
        "### Prompt Formatting\n",
        "Use separators to separte prompt content and additional data\n",
        "\n",
        "    - triple backticks ```\n",
        "    - triple quotes \"\"\" and '''\n",
        "    - triple hyphen ---\n",
        "    - XML tags <start> </start>\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oWBp_01erK5",
        "outputId": "009b8baf-d320-4e51-9211-9fcb94433121"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My age is 29\n"
          ]
        }
      ],
      "source": [
        "print(\"My age is %d\"%(29))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xxYuxederK6",
        "outputId": "74a20f5c-c44c-4cd8-dfa2-cc304f2784a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Hi, My name is Anshu and my age is 29\n"
          ]
        }
      ],
      "source": [
        "# f string\n",
        "age = 29\n",
        "name = 'Anshu'\n",
        "text = f\" Hi, My name is {name} and my age is {age}\"\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjHresN3erK6",
        "outputId": "c3f7e730-74c1-460f-b09f-b63c4262e115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summarize the below content separated by triple bckticks.\n",
            "This is to be used to put in a social media post on twitter.\n",
            "\n",
            "Content:\n",
            "```\n",
            "Morningstar, Inc. is an American financial services firm headquartered in Chicago, Illinois, founded by Joe Mansueto in 1984. It provides an array of investment research and investment management services.\n",
            "With operations in 29 countries, Morningstar's research and recommendations are considered by financial journalists as influential in the asset management industry, and a positive or negative recommendation from Morningstar analysts can drive money into or away from any given fund.[3][4] Through its asset management division, the firm currently manages over US$295 billion as of March 31, 2023.[5]\n",
            "The firm also provides software and data platforms for investment professionals, including \"Morningstar Research Portal\", \"Morningstar Direct\" and \"Morningstar Advisor Workstation\".\n",
            "    \n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "content = \"\"\"Morningstar, Inc. is an American financial services firm headquartered in Chicago, Illinois, founded by Joe Mansueto in 1984. It provides an array of investment research and investment management services.\n",
        "With operations in 29 countries, Morningstar's research and recommendations are considered by financial journalists as influential in the asset management industry, and a positive or negative recommendation from Morningstar analysts can drive money into or away from any given fund.[3][4] Through its asset management division, the firm currently manages over US$295 billion as of March 31, 2023.[5]\n",
        "The firm also provides software and data platforms for investment professionals, including \"Morningstar Research Portal\", \"Morningstar Direct\" and \"Morningstar Advisor Workstation\".\n",
        "    \"\"\"\n",
        "\n",
        "prompt = f\"\"\"Summarize the below content separated by triple bckticks.\n",
        "This is to be used to put in a social media post on twitter.\n",
        "\n",
        "Content:\n",
        "```\n",
        "{content}\n",
        "```\n",
        "\"\"\"\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbIQHpGP4cL7",
        "outputId": "dd132cbb-0184-49b7-eb11-a93999a7e622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Morningstar, Inc., founded in 1984 by Joe Mansueto, is a leading financial services firm based in Chicago. With operations in 29 countries, it offers investment research and management services, influencing the asset management industry. As of March 31, 2023, they manage over $295 billion and provide essential software for investment professionals. #Finance #Investing #Morningstar\n"
          ]
        }
      ],
      "source": [
        "output = generate_response(prompt)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKpUcp3Z3ATA"
      },
      "source": [
        "### Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5EuohXyerK7",
        "outputId": "80038327-5a05-4e60-cf36-5776fa16e125"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is a Markdown table with the names of six animals along with their genus and species:\n",
            "\n",
            "```markdown\n",
            "| Animal          | Genus      | Species          |\n",
            "|-----------------|------------|------------------|\n",
            "| African Elephant| Loxodonta  | Loxodonta africana|\n",
            "| Bengal Tiger    | Panthera   | Panthera tigris  |\n",
            "| Common Frog     | Rana       | Rana temporaria   |\n",
            "| Gray Wolf       | Canis      | Canis lupus      |\n",
            "| Giant Panda     | Ailuropoda | Ailuropoda melanoleuca |\n",
            "| American Bald Eagle | Haliaeetus | Haliaeetus leucocephalus |\n",
            "```\n",
            "\n",
            "Feel free to ask if you need more information!\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"write name of 6 animals, their genus and spiecies.\n",
        "Provide output in Markdown Table format. \"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNkxKCY_45P9",
        "outputId": "8ddd4b73-b2a0-4e76-dace-492443bfe387"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- African Elephant: Genus - Loxodonta, Species - Loxodonta africana\n",
            "- Bengal Tiger: Genus - Panthera, Species - Panthera tigris tigris\n",
            "- Common House Cat: Genus - Felis, Species - Felis catus\n",
            "- Gray Wolf: Genus - Canis, Species - Canis lupus\n",
            "- American Bald Eagle: Genus - Haliaeetus, Species - Haliaeetus leucocephalus\n",
            "- Green Sea Turtle: Genus - Chelonia, Species - Chelonia mydas\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"write name of 6 animals, their genus and spiecies.\n",
        "Provide output in plain text bullet points format. \"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvLIFGbHerK7",
        "outputId": "5ebb6e78-da5e-4c4c-f2b9-bf736d429646"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is a list of 10 roles specific to Data and AI, along with their associated skills and tools, formatted in JSON:\n",
            "\n",
            "```json\n",
            "[\n",
            "    {\n",
            "        \"role\": \"Data Scientist\",\n",
            "        \"skills\": [\"Statistical Analysis\", \"Machine Learning\", \"Data Visualization\", \"Programming (Python, R)\", \"Data Wrangling\"],\n",
            "        \"tools\": [\"Jupyter Notebook\", \"Pandas\", \"Scikit-learn\", \"Matplotlib\", \"TensorFlow\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Data Engineer\",\n",
            "        \"skills\": [\"ETL Processes\", \"Database Management\", \"Big Data Technologies\", \"Data Warehousing\", \"Programming (Python, Java, Scala)\"],\n",
            "        \"tools\": [\"Apache Spark\", \"Apache Kafka\", \"SQL\", \"AWS Redshift\", \"Airflow\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Machine Learning Engineer\",\n",
            "        \"skills\": [\"Machine Learning Algorithms\", \"Model Deployment\", \"Software Engineering\", \"Data Preprocessing\", \"Cloud Computing\"],\n",
            "        \"tools\": [\"TensorFlow\", \"PyTorch\", \"Docker\", \"Kubernetes\", \"MLflow\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"AI Research Scientist\",\n",
            "        \"skills\": [\"Deep Learning\", \"Natural Language Processing\", \"Computer Vision\", \"Research Methodologies\", \"Mathematics\"],\n",
            "        \"tools\": [\"TensorFlow\", \"PyTorch\", \"Keras\", \"OpenAI Gym\", \"SciPy\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Data Analyst\",\n",
            "        \"skills\": [\"Data Analysis\", \"Data Visualization\", \"Statistical Techniques\", \"Excel\", \"SQL\"],\n",
            "        \"tools\": [\"Tableau\", \"Power BI\", \"Excel\", \"SQL\", \"Google Analytics\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Business Intelligence Analyst\",\n",
            "        \"skills\": [\"Data Modeling\", \"Data Visualization\", \"Business Acumen\", \"SQL\", \"Reporting\"],\n",
            "        \"tools\": [\"Tableau\", \"Power BI\", \"Looker\", \"SQL Server\", \"Google Data Studio\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Data Architect\",\n",
            "        \"skills\": [\"Database Design\", \"Data Modeling\", \"Big Data Technologies\", \"Cloud Services\", \"Data Governance\"],\n",
            "        \"tools\": [\"AWS, Azure, GCP\", \"Apache Hadoop\", \"MongoDB\", \"Oracle\", \"ERwin Data Modeler\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"AI Product Manager\",\n",
            "        \"skills\": [\"Product Management\", \"AI/ML Knowledge\", \"Market Research\", \"Agile Methodologies\", \"Stakeholder Management\"],\n",
            "        \"tools\": [\"Jira\", \"Trello\", \"Confluence\", \"Aha!\", \"Google Analytics\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Data Quality Analyst\",\n",
            "        \"skills\": [\"Data Quality Assessment\", \"Data Profiling\", \"Data Cleansing\", \"SQL\", \"Attention to Detail\"],\n",
            "        \"tools\": [\"Talend\", \"Informatica\", \"Apache Nifi\", \"SQL\", \"Python\"]\n",
            "    },\n",
            "    {\n",
            "        \"role\": \"Ethics in AI Specialist\",\n",
            "        \"skills\": [\"Ethical Frameworks\", \"Regulatory Compliance\", \"Risk Assessment\", \"Stakeholder Engagement\", \"Research\"],\n",
            "        \"tools\": [\"Ethical AI Frameworks\", \"Data Governance Tools\", \"Compliance Management Software\", \"Surveys\", \"Interviews\"]\n",
            "    }\n",
            "]\n",
            "```\n",
            "\n",
            "This JSON structure provides a clear overview of various roles in the Data and AI field, along with the skills and tools associated with each role.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"create a list of 10 roles specific to Data and AI, provide skills and tools used for each.\n",
        "Provide output in JSON format with keys: role, skills, tools. \"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y54erqcRerK7",
        "outputId": "197e8153-e3e7-45b5-8066-94e373c186c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "role,skills,tools  \n",
            "Data Scientist,Statistical Analysis; Machine Learning; Data Visualization; Programming; Data Wrangling,Pandas; NumPy; Scikit-learn; Matplotlib; TensorFlow  \n",
            "Machine Learning Engineer,Machine Learning; Software Engineering; Model Deployment; Data Preprocessing; Cloud Computing,TensorFlow; PyTorch; Docker; Kubernetes; AWS  \n",
            "Data Analyst,Data Analysis; SQL; Data Visualization; Reporting; Business Intelligence,Tableau; Power BI; SQL; Excel; R  \n",
            "AI Research Scientist,Research Methodology; Machine Learning; Deep Learning; Programming; Data Analysis,Pytorch; TensorFlow; Jupyter; Git; LaTeX  \n",
            "Data Engineer,Data Modeling; ETL Processes; Database Management; Big Data Technologies; Cloud Services,Apache Spark; Hadoop; SQL; AWS; Kafka  \n",
            "Business Intelligence Developer,Data Warehousing; SQL; Data Visualization; Reporting; Business Acumen,Tableau; Power BI; SQL Server; Looker; Oracle  \n",
            "AI Product Manager,Product Management; Market Research; Data Analysis; Communication; Agile Methodologies,JIRA; Trello; Confluence; Google Analytics; Aha!  \n",
            "Data Architect,Data Modeling; Database Design; Cloud Architecture; Data Governance; Big Data Technologies,AWS; Azure; Google Cloud; SQL; NoSQL  \n",
            "Machine Learning Researcher,Statistical Analysis; Algorithm Development; Programming; Experimentation; Data Analysis,Python; R; TensorFlow; Scikit-learn; MATLAB  \n",
            "AI Ethics Specialist,Ethics in AI; Policy Development; Risk Assessment; Communication; Research,Python; R; Jupyter; Git; Microsoft Office\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"create a list of 10 roles specific to Data and AI, provide skills and tools used for each.\n",
        "Provide output in CSV format with headers: role, skills, tools.\n",
        "Keep the multiple tools and skills within column seperated by semicolon.\n",
        "Do not provide any other additional, sa the response will be further appended in csv file dicrectly.\"\"\"\n",
        "output = generate_response(prompt)\n",
        "\n",
        "import re\n",
        "def clean_response(text):\n",
        "    text = re.sub('```csv','',text)\n",
        "    text = re.sub(\"```\",'',text)\n",
        "    return text.strip()\n",
        "\n",
        "output = clean_response(output)\n",
        "print(output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "xnFnCUATerK8"
      },
      "outputs": [],
      "source": [
        "with open(\"roles.csv\",\"w\") as file:\n",
        "    file.write(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H2qcAHIerK8",
        "outputId": "af71763c-7905-4840-bc5c-deaea446c295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import pandas as pd\n",
            "\n",
            "# Read the CSV file\n",
            "df = pd.read_csv('roles.csv')\n",
            "\n",
            "# Export to JSON format\n",
            "df.to_json('roles.json', orient='records', lines=True)\n",
            "\n",
            "# Print success message\n",
            "print(\"Exported roles.csv to roles.json successfully.\")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "input_file = \"roles.csv\"\n",
        "prompt = f\"\"\" write python code to read the file {input_file} and export it to a JSON format using pandas.\n",
        "print success message at the end\n",
        "write code which can directly be executed, do not add any additional text/explaantion, if any use # (comment to mention)\n",
        "\"\"\"\n",
        "def clean_response(text):\n",
        "    text = re.sub('```python','',text)\n",
        "    text = re.sub(\"```\",'',text)\n",
        "    return text.strip()\n",
        "llmcode = generate_response(prompt)\n",
        "llmcode = clean_response(llmcode)\n",
        "print(llmcode)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agitgR47erK8",
        "outputId": "1f579ef1-f525-47e4-f13c-0ac8ea2054da"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Anshu Pandey\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
            "  from pandas.core import (\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exported roles.csv to roles.json successfully.\n"
          ]
        }
      ],
      "source": [
        "exec(llmcode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task\n",
        "Userinput: Domain (e.g. Finance / Telecom / Healthcare)\n",
        "\n",
        "LLM output: a table to map use cases in the domain for 1. Prompt based solutions, 2. static workflows with LLMs, 3. Agentic Workflows, 4. RAG workflows\n",
        "\n",
        "For each category 2 use cases. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Design Pattern               | UC1                                           | UC2                                           |\n",
            "|------------------------------|----------------------------------------------|----------------------------------------------|\n",
            "| Prompt Based Solutions        | Automated financial report generation        | Personalized investment advice               |\n",
            "| Static Workflows with LLMs    | Loan application processing                  | Fraud detection report generation            |\n",
            "| Agentic Workflows            | Virtual financial advisor for clients        | Automated tax filing assistance               |\n",
            "| RAG Workflows                | Real-time market analysis and insights       | Customer support for account inquiries       |\n"
          ]
        }
      ],
      "source": [
        "domain = \"finance\"\n",
        "prompt = f\"\"\" You are an expert Generative AI Consultant who comes with expertise in identifying relevant use cases for the provided domain.\n",
        "create a table of use cases for the provided domain {domain}. \n",
        "Use cases should be spread across generative ai design patterns such as Prompt Based solutions, Static Workflows with LLMs, Agentic Workflows, RAG Workflows.\n",
        "Create  a table with columns: Design Pattern, UC1, UC2: need two cases for every design pattern\n",
        "Do not generate any addition text after the table.\n",
        "\"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uZaWtT8erK9",
        "outputId": "5c30cd18-203e-4f14-ef8f-f082e4c4e281"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Summary\n",
            "Morningstar, Inc. is a financial services firm based in Chicago, Illinois, founded in 1984 by Joe Mansueto. The company offers investment research and management services and operates in 29 countries. Its research is highly regarded in the asset management industry, with recommendations from Morningstar analysts significantly influencing fund investments. As of March 31, 2023, Morningstar manages over $295 billion in assets. Additionally, the firm provides software and data platforms for investment professionals, including the \"Morningstar Research Portal,\" \"Morningstar Direct,\" and \"Morningstar Advisor Workstation.\"\n",
            "\n",
            "### Translation to French\n",
            "Morningstar, Inc. est une entreprise de services financiers base  Chicago, Illinois, fonde en 1984 par Joe Mansueto. L'entreprise propose des services de recherche et de gestion d'investissements et opre dans 29 pays. Ses recherches sont trs respectes dans l'industrie de la gestion d'actifs, les recommandations des analystes de Morningstar influenant considrablement les investissements dans les fonds. Au 31 mars 2023, Morningstar gre plus de 295 milliards de dollars d'actifs. De plus, l'entreprise fournit des logiciels et des plateformes de donnes pour les professionnels de l'investissement, y compris le \"Morningstar Research Portal\", \"Morningstar Direct\" et \"Morningstar Advisor Workstation\".\n",
            "\n",
            "### Locations\n",
            "- Chicago, Illinois, USA\n",
            "\n",
            "### JSON\n",
            "```json\n",
            "{\n",
            "  \"summary\": \"Morningstar, Inc. is a financial services firm based in Chicago, Illinois, founded in 1984 by Joe Mansueto. The company offers investment research and management services and operates in 29 countries. Its research is highly regarded in the asset management industry, with recommendations from Morningstar analysts significantly influencing fund investments. As of March 31, 2023, Morningstar manages over $295 billion in assets. Additionally, the firm provides software and data platforms for investment professionals, including the 'Morningstar Research Portal,' 'Morningstar Direct,' and 'Morningstar Advisor Workstation.'\",\n",
            "  \"translation\": \"Morningstar, Inc. est une entreprise de services financiers base  Chicago, Illinois, fonde en 1984 par Joe Mansueto. L'entreprise propose des services de recherche et de gestion d'investissements et opre dans 29 pays. Ses recherches sont trs respectes dans l'industrie de la gestion d'actifs, les recommandations des analystes de Morningstar influenant considrablement les investissements dans les fonds. Au 31 mars 2023, Morningstar gre plus de 295 milliards de dollars d'actifs. De plus, l'entreprise fournit des logiciels et des plateformes de donnes pour les professionnels de l'investissement, y compris le 'Morningstar Research Portal', 'Morningstar Direct' et 'Morningstar Advisor Workstation.'\",\n",
            "  \"locations\": [\n",
            "    {\n",
            "      \"city\": \"Chicago\",\n",
            "      \"state\": \"Illinois\",\n",
            "      \"country\": \"USA\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "content = \"\"\"Morningstar, Inc. is an American financial services firm headquartered in Chicago, Illinois, founded by Joe Mansueto in 1984. It provides an array of investment research and investment management services.\n",
        "With operations in 29 countries, Morningstar's research and recommendations are considered by financial journalists as influential in the asset management industry, and a positive or negative recommendation from Morningstar analysts can drive money into or away from any given fund.[3][4] Through its asset management division, the firm currently manages over US$295 billion as of March 31, 2023.[5]\n",
        "The firm also provides software and data platforms for investment professionals, including \"Morningstar Research Portal\", \"Morningstar Direct\" and \"Morningstar Advisor Workstation\".\n",
        "    \"\"\"\n",
        "\n",
        "prompt = f\"\"\" Summarize below content separated by triple backticks, translate it to french, provide name of locaitons\n",
        "and a JSON with everything.\n",
        "\n",
        "content:\n",
        "```{content}```\n",
        "\"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVefCX-AerK9",
        "outputId": "e4dd5cc2-c5dc-4adc-82df-0c7abb3dfd0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"summary\": \"Morningstar, Inc. is a financial services firm based in Chicago, Illinois, founded in 1984 by Joe Mansueto. It offers investment research and management services, operating in 29 countries. Morningstar's recommendations are influential in the asset management industry, impacting fund investments. As of March 31, 2023, it manages over $295 billion. The firm also provides software and data platforms for investment professionals.\",\n",
            "  \"summary_french\": \"Morningstar, Inc. est une socit de services financiers base  Chicago, Illinois, fonde en 1984 par Joe Mansueto. Elle propose des services de recherche et de gestion d'investissements, oprant dans 29 pays. Les recommandations de Morningstar sont influentes dans l'industrie de la gestion d'actifs, impactant les investissements dans les fonds. Au 31 mars 2023, elle gre plus de 295 milliards de dollars. La socit propose galement des logiciels et des plateformes de donnes pour les professionnels de l'investissement.\",\n",
            "  \"locations\": [\n",
            "    \"Chicago, Illinois\",\n",
            "    \"29 countries\"\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"Perform following tasks:\n",
        "1. Summarize below content separated by triple backticks\n",
        "2. translate summary to french\n",
        "3. Extract name of locaitons from content\n",
        "4. Provide a JSON with everything.\n",
        "\n",
        "content:\n",
        "```{content}```\n",
        "\"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPHJl-_tA7O0"
      },
      "source": [
        "## Hallucinations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0nS2q4BerK-",
        "outputId": "7f2de547-1392-42a9-987e-4b089317ca1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Gather warm water and mix it with some detergent.  \n",
            "Step 2: Place the dirty clothes into the mixture and let them soak for a while.  \n",
            "Step 3: After soaking, remove the clothes and use a soft brush to rub out any dirt or stains.  \n",
            "Step 4: Rinse the clothes in clean water to remove the detergent.  \n",
            "Step 5: Hang the clothes on a rope to dry.  \n",
            "Step 6: Enjoy your clean clothes!\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "Washing clothes without washing machines is easy!\n",
        "First you need to get some warm water. Mix the warm water with some detergent. Second you can put the dirty clothes in it and let it stay wet for some time.\n",
        "During this period the stains will get loose and mixed with water.\n",
        "thereafter you can take clothes out, rub the dirt/stains with a soft brush to remove the stains if any.\n",
        "get the clothes mixed with water to get the detergent out of it. and then put it for drying on a rope.\n",
        "Enjoy the clean clothes.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks. Rewrite those into a set of instructions in the following format:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDlUmltEBLd7",
        "outputId": "5fc766e7-d07d-4389-a4c9-660ebb873363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Observe the morning weather and note that it is amazing.  \n",
            "Step 2: Look at the sun shining brightly between the clouds.  \n",
            "Step 3: Appreciate the pleasant weather conditions.  \n",
            "Step 4: Feel the refreshing wind and acknowledge its mindblowing quality.  \n",
            "Step 5: Reflect on your overall enjoyment of the day.\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "The morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing.\n",
        "on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks. Rewrite those into a set of instructions in the following format:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSbZxYCVBbx7",
        "outputId": "a336bf0d-3408-49d9-9353-8d206957229d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1: Get some warm water and mix it with detergent.  \n",
            "Step 2: Put the dirty clothes in the mixture and let them stay wet for some time.  \n",
            "Step 3: Take the clothes out and rub the dirt/stains with a soft brush to remove any stains.  \n",
            "Step 4: Rinse the clothes with water to get the detergent out.  \n",
            "Step 5: Hang the clothes on a rope to dry.  \n",
            "Step 6: Enjoy the clean clothes.\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "Washing clothes without washing machines is easy!\n",
        "First you need to get some warm water. Mix the warm water with some detergent. Second you can put the dirty clothes in it and let it stay wet for some time.\n",
        "During this period the stains will get loose and mixed with water.\n",
        "thereafter you can take clothes out, rub the dirt/stains with a soft brush to remove the stains if any.\n",
        "get the clothes mixed with water to get the detergent out of it. and then put it for drying on a rope.\n",
        "Enjoy the clean clothes.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks.\n",
        "Rewrite those into a set of instructions in the following format only if contains a sequence of instructions:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\n",
        "if the text does not contain a sequence of instructions, then simply write 'No steps provided'\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_16NJitB9xp",
        "outputId": "9ed6b07e-759c-46a0-cb10-6ecf72ef9918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No steps provided\n"
          ]
        }
      ],
      "source": [
        "# asking for a specific format\n",
        "text = \"\"\"\n",
        "The morning today is amazing, the sun is looking bright in between clouds, the weather is pleasent and the wind is mindblowing.\n",
        "on a whole i am loving the day today.\n",
        "\"\"\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "you will be provided with some text delimited by triple backticks.\n",
        "Rewrite those into a set of instructions in the following format only if contains a sequence of instructions:\n",
        "\n",
        "Step 1: ...\n",
        "Step 2: ....\n",
        "..\n",
        "Step N:...\n",
        "\n",
        "```{text}\n",
        "```\n",
        "\n",
        "if the text does not contain a sequence of instructions, then simply write 'No steps provided'\n",
        "\"\"\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDWT_m3rCB1_",
        "outputId": "c4afe2b6-6080-4543-8d52-5c625f082e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. **Delhi**: A vibrant blend of ancient history and modernity, Delhi is India's bustling capital known for its rich culture, diverse cuisine, and historical landmarks.  \n",
            "2. **Manila**: The capital of the Philippines, Manila is a lively metropolis characterized by its colonial architecture, vibrant street life, and rich cultural heritage.  \n",
            "3. **FILcity**: A fictional urban landscape that embodies the essence of Filipino culture, innovation, and community spirit, showcasing a harmonious blend of tradition and modern living.  \n",
            "4. **Kuala Lumpur**: Malaysia's capital, Kuala Lumpur is famous for its iconic Petronas Twin Towers, diverse population, and a dynamic mix of cultures and cuisines.  \n",
            "5. **Dubai**: A dazzling city in the UAE known for its futuristic skyline, luxury shopping, and extravagant lifestyle, blending tradition with cutting-edge innovation.  \n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"write one line description for below cities:\n",
        "\n",
        "1. Delhi\n",
        "2. Manila\n",
        "3. FILcity\n",
        "4. Kuala Lumpur\n",
        "5. Dubai\n",
        "\"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoYh60OwCZzy",
        "outputId": "99e59883-496c-48ce-801a-660ef4da457d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. **Delhi**: The bustling capital of India, known for its rich history, diverse culture, and vibrant street life.  \n",
            "2. **Manila**: The capital city of the Philippines, famous for its historic sites, lively atmosphere, and as a major cultural and economic hub.  \n",
            "3. **JPchasecity**: The city does not exist as per my knowledge.  \n",
            "4. **Kuala Lumpur**: The capital of Malaysia, renowned for its modern skyline, including the iconic Petronas Twin Towers, and a melting pot of cultures.  \n",
            "5. **Dubai**: A global city in the UAE known for its luxury shopping, ultramodern architecture, and vibrant nightlife.  \n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"write one line description for below cities:\n",
        "\n",
        "1. Delhi\n",
        "2. Manila\n",
        "3. JPchasecity\n",
        "4. Kuala Lumpur\n",
        "5. Dubai\n",
        "\n",
        "\n",
        "\n",
        "CHeck if the city is the actual city as per your knowledge base / cutoff data, if not mention that \"The city does not exist as per my knowledge\"\n",
        "\"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIUgiYwmC1MO",
        "outputId": "790ca0dd-ada3-4975-cc42-905089d2d944"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. **Chase Credit Card**: The Chase Credit Card offers a versatile financial solution designed to meet the needs of everyday consumers and savvy spenders alike. With competitive rewards programs, low introductory APRs, and robust security features, this credit card empowers users to manage their finances effectively while earning points on purchases. Whether you're looking to build credit, earn cashback, or enjoy travel benefits, the Chase Credit Card provides a reliable and user-friendly experience backed by Chase's extensive banking expertise.\n",
            "\n",
            "   *Realism Analysis*: Chase is a well-known financial institution that offers a variety of credit cards, making this product realistic and aligned with their offerings.\n",
            "\n",
            "2. **Fidelity Ergonomic Toothbrush**: The Fidelity Ergonomic Toothbrush is designed with both comfort and effectiveness in mind, promoting optimal oral hygiene while reducing strain on your hands and wrists. Featuring a unique handle shape that fits naturally in your grip, this toothbrush ensures a thorough clean with its soft bristles that are gentle on gums. Ideal for users of all ages, the Fidelity Ergonomic Toothbrush combines innovative design with practical functionality to enhance your daily dental care routine.\n",
            "\n",
            "   *Realism Analysis*: I do not have context knowledge about the product. Fidelity is primarily known for financial services, and there is no widely recognized association with dental products.\n",
            "\n",
            "3. **JP Morgan Relax Chair**: The JP Morgan Relax Chair is a luxurious seating solution designed to provide ultimate comfort and support for those seeking a moment of tranquility in their busy lives. Crafted with high-quality materials and ergonomic design principles, this chair features adjustable settings to cater to individual preferences, making it perfect for home or office use. With its sleek aesthetic and superior comfort, the JP Morgan Relax Chair is an ideal addition to any space, promoting relaxation and well-being.\n",
            "\n",
            "   *Realism Analysis*: I do not have context knowledge about the product. JP Morgan is primarily a financial services firm and does not typically produce furniture or similar products.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"write one description for below products:\n",
        "\n",
        "1. A credit card by Chase\n",
        "2. An ergonomic Toothbrush by Fidelity\n",
        "3. A relax chair by JP Morgan\n",
        "\n",
        "Analyze if the product is realistic, the company actually works and produces similar products, if not say: I do not have context knowledge about the product.\n",
        "\"\"\"\n",
        "print(generate_response(prompt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "jM2oDOMYDL6J"
      },
      "outputs": [],
      "source": [
        "# creating a function to get outcome\n",
        "def generate_response(prompt,model='gpt4o',temperature=0,stream=False):\n",
        "  messages = [{\"role\":\"user\",\"content\":prompt}]\n",
        "  response = client.chat.completions.create(\n",
        "      model = model,\n",
        "      messages = messages,\n",
        "      temperature=temperature,\n",
        "      stream=stream\n",
        "      #top_p=0.99\n",
        "  )\n",
        "  return response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voWbPlIAFY29",
        "outputId": "e1bfe54a-0f38-45b4-cd05-4a4c4358f30f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionChunk(id='', choices=[], created=0, model='', object='', service_tier=None, system_fingerprint=None, usage=None, prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='', function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='1', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' **', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='Delhi', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='**', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' A', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' vibrant', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' metropolis', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' that', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' blends', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' rich', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' history', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' with', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' modern', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='ity', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' serving', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' as', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' capital', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' of', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' India', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='  \\n', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='2', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' **', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='Man', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='ila', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='**', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' The', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' bustling', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' capital', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' of', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' Philippines', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' known', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' its', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' historic', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' sites', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' vibrant', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' culture', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='  \\n', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='3', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' **', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='JP', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='ch', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='ase', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='city', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='**', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' The', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' city', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' does', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' not', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' exist', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' as', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' per', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' my', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' knowledge', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='  \\n', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='4', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' **', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='K', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='uala', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' Lumpur', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='**', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' Malaysia', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=\"'s\", function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' capital', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' famous', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' its', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' iconic', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' Pet', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='ron', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='as', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' Twin', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' Towers', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' diverse', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' cultural', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' heritage', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='  \\n', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='5', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' **', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='Dubai', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='**', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=':', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' A', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' luxurious', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' city', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' in', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' the', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' UAE', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' renowned', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' for', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' its', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' futuristic', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' architecture', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' shopping', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=',', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' and', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' vibrant', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=' nightlife', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='.', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content='  ', function_call=None, refusal=None, role=None, tool_calls=None), finish_reason=None, index=0, logprobs=None, content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n",
            "ChatCompletionChunk(id='chatcmpl-CBuLtClLUGwQk6OmbQW6kBBfa2DeT', choices=[Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='stop', index=0, logprobs=None, content_filter_results={})], created=1756954261, model='gpt-4o-mini-2024-07-18', object='chat.completion.chunk', service_tier=None, system_fingerprint='fp_efad92c60b', usage=None)\n"
          ]
        }
      ],
      "source": [
        "prompt = \"\"\"write one line description for below cities:\n",
        "\n",
        "1. Delhi\n",
        "2. Manila\n",
        "3. JPchasecity\n",
        "4. Kuala Lumpur\n",
        "5. Dubai\n",
        "\n",
        "\n",
        "\n",
        "CHeck if the city is the actual city as per your knowledge base / cutoff data, if not mention that \"The city does not exist as per my knowledge\"\n",
        "\"\"\"\n",
        "streams = generate_response(prompt,stream=True)\n",
        "\n",
        "for event in streams:\n",
        "  print(event)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "IzG98srNFsV1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6TvQ89UdF6De"
      },
      "outputs": [],
      "source": [
        "|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWYDUVa1JZb9"
      },
      "source": [
        "## Exercise 1: Prompting for Product Explanation (with Compliance)\n",
        "\n",
        "**Objective:** Design a prompt for an AI to explain a banking product accurately and compliantly.\n",
        "\n",
        "**Scenario:** A customer asks about a \"Fixed Deposit\" in a Saudi bank. The AI needs to explain it clearly, including key details, and add a standard compliance disclaimer.\n",
        "\n",
        "**Task:** Create a prompt for an AI to explain a Fixed Deposit.\n",
        "\n",
        "**Prompt Requirements:**\n",
        "1.  **Role:**\n",
        "2.  **Instruction:**\n",
        "3.  **Key Details to Include:**\n",
        "4.  **Compliance Constraint:**\n",
        "5.  **Tone:**\n",
        "\n",
        "---\n",
        "\n",
        "**Example Input for Testing:**\n",
        "\n",
        "**User Query:** \"What is a Fixed Deposit and how does it work?\"\n",
        "\n",
        "---\n",
        "\n",
        "**Example Output (Simulated AI Response based on your prompt):**\n",
        "\n",
        "\"As a Bank Customer Service Officer, I can explain Fixed Deposits for you.\n",
        "\n",
        "A Fixed Deposit is an investment account that holds a fixed amount of money for a specified period, offering a fixed interest rate. You earn interest on your deposit, which is typically paid out at the end of the maturity period. If you withdraw your funds before the agreed maturity date, a penalty may apply, often resulting in forfeiture of accrued interest.\n",
        "\n",
        "*Terms and conditions apply. Interest rates are subject to change without prior notice.*\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZmU5JQPJZ4Y",
        "outputId": "0f310c3b-7243-4f2f-cd48-da55bb513cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dear Customer,\n",
            "\n",
            "Thank you for your interest in our Fixed Deposit product. \n",
            "\n",
            "**What is a Fixed Deposit?**  \n",
            "A Fixed Deposit (FD) is a savings account where you deposit a lump sum amount for a fixed period of time, earning a higher interest rate than a regular savings account. The money remains locked in for the duration of the term, and you receive the principal amount plus interest at maturity.\n",
            "\n",
            "**Key Attributes of Fixed Deposit:**\n",
            "- **Interest Rates:** Fixed Deposits typically offer higher interest rates compared to regular savings accounts. The rate is fixed for the entire term.\n",
            "- **Maturity:** You can choose the duration of your deposit, which can range from a few months to several years.\n",
            "- **Penalties:** If you withdraw your funds before the maturity date, a penalty may apply, which could reduce the interest earned.\n",
            "\n",
            "**Example of Calculations:**\n",
            "Lets say you deposit SAR 10,000 in a Fixed Deposit for 1 year at an interest rate of 5% per annum. \n",
            "\n",
            "- **Interest Earned:** \n",
            "  - Interest = Principal x Rate x Time\n",
            "  - Interest = SAR 10,000 x 5% x 1 = SAR 500\n",
            "\n",
            "At maturity, you would receive:\n",
            "- **Total Amount = Principal + Interest = SAR 10,000 + SAR 500 = SAR 10,500.**\n",
            "\n",
            "If you decide to withdraw early, lets say after 6 months, you may incur a penalty that could reduce your interest to SAR 250 instead of SAR 500.\n",
            "\n",
            "If you have any further questions or need assistance, please feel free to ask.\n",
            "\n",
            "**Disclaimer:** Terms and conditions apply. Interest rates are subject to change without prior notice.\n",
            "\n",
            "Best regards,  \n",
            "[Your Name]  \n",
            "Senior Customer Service Officer  \n",
            "Saudi Asia Bank\n"
          ]
        }
      ],
      "source": [
        "\n",
        "product_name=\"Fixed Deposit\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "\n",
        "You are a senior customer service officer from Saudi Asia Bank, who always explains the banking products in clear, simpler ways.\n",
        "Explain the product to ther customer: {product_name}\n",
        "\n",
        "Your explanation must include:\n",
        "- A clear defintion of the product: {product_name}\n",
        "- Attributes applicable to the product {product_name} such as interest rates, maturity, penalties\n",
        "- Examples of calculations\n",
        "- Keep overall response concise and clear\n",
        "\n",
        "Maintain a professional, easy to understand, and soft tone.\n",
        "At the end of the message, always add a disclaimer: Terms and conditions apply. Interest rates are subject to change without prior notice.\n",
        "\"\"\"\n",
        "\n",
        "print(generate_response(prompt).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0gHrmzNJeHi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmoEyLrmJeea"
      },
      "source": [
        "\n",
        "## Exercise 2: Iterative Prompt Refinement for Transaction Categorization\n",
        "\n",
        "**Objective:** Refine a prompt to categorize customer transactions accurately and concisely, reducing irrelevant information.\n",
        "\n",
        "**Scenario:** Your bank's AI system categorizes customer spending. The initial prompt is too broad, leading to generic or noisy outputs.\n",
        "\n",
        "**Initial Prompt (Provided to AI):**\n",
        "\"Categorize the following transaction: 'Purchase at Starbucks, USD15'.\"\n",
        "\n",
        "**AI's Initial Output:**\n",
        "\"This transaction is for coffee. It is a small expense. It happened at Starbucks.\"\n",
        "\n",
        "---\n",
        "\n",
        "**Task:** Perform two iterations of prompt refinement.\n",
        "\n",
        "**Iteration 1: Improving Specificity & Conciseness**\n",
        "\n",
        "* **Goal:** Get a precise category without unnecessary conversational filler.\n",
        "* **Prompt Engineering Principles:** Specificity, Negative Constraints (implied by what *not* to include).\n",
        "\n",
        "**Your Revised Prompt (Iteration 1):**\n",
        "\n",
        "\n",
        "**Example Output (Example Response based on your Iteration 1 prompt):**\n",
        "\n",
        "\"Food & Beverage\"\n",
        "\n",
        "---\n",
        "\n",
        "**Iteration 2: Adding Detail and Format for Analyst Review**\n",
        "\n",
        "* **Goal:** Provide the category and a *reason* for that category, formatted for a data analyst.\n",
        "* **Prompt Engineering Principles:** Role-Playing, Chain-of-Thought (implicit), Format.\n",
        "\n",
        "**Your Revised Prompt (Iteration 2):**\n",
        "\n",
        "\n",
        "**Example Output (Example Response based on your Iteration 2 prompt):**\n",
        "\n",
        "\"**Category: Food & Beverage**\n",
        "**Reasoning:** 'Starbucks' is a common coffee shop, and 'USD15' is a typical amount for such a purchase.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFWMAbcJJeux",
        "outputId": "4067287b-f8ab-4ea7-d06f-2e9007324dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Food & Beverage\n"
          ]
        }
      ],
      "source": [
        "transaction_details=\"Purchase at Starbucks, USD15\"\n",
        "prompt = f\"\"\"\n",
        "You are seasoned accounts book keeper who is able to categorize transactions by going through bank statements.\n",
        "Categorise the given {transaction_details} from below list,\n",
        "1. food & Beverage\n",
        "2. Travel\n",
        "3. Clothing\n",
        "Your response should include only category\n",
        "\"\"\"\n",
        "print(generate_response(prompt).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TltMrS5TpQs",
        "outputId": "fd3676bc-1a09-471d-d5bc-bec1ee6cea10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```json\n",
            "{\n",
            "  \"category\": \"Food & Beverage\",\n",
            "  \"reasoning\": \"The purchase at Starbucks is for food and beverage items, which directly falls under the Food & Beverage category. Starbucks primarily sells coffee, snacks, and other related products, making it clear that this transaction is related to consumable goods rather than travel or clothing.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "transaction_details=\"Purchase at Starbucks, USD15\"\n",
        "prompt = f\"\"\"\n",
        "You are seasoned accounts book keeper who is able to categorize transactions by going through bank statements.\n",
        "Categorise the given {transaction_details} from below list,\n",
        "1. Food & Beverage\n",
        "2. Travel\n",
        "3. Clothing\n",
        "\n",
        "Defint the reasoning for categorizing the transaction details into the specific category.\n",
        "Provide the final response in JSON format with keys: category, reasoning\n",
        "\"\"\"\n",
        "print(generate_response(prompt).choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db7aOlG1UIdk"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
