{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "QOQ7oa5QW5QQ",
      "metadata": {
        "id": "QOQ7oa5QW5QQ"
      },
      "source": [
        "# ðŸš€ PromptOps with LangSmith and Azure OpenAI\n",
        "\n",
        "This Jupyter Notebook provides a step-by-step guide on implementing **Prompt Operations (PromptOps)** using **LangSmith** for prompt management, **LangChain** for orchestration, and **Azure OpenAI** for content generation. We will cover the entire lifecycle: prompt registration, modification, loading, generation and deletion.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Before running the code, ensure you have the following environment variables set up. These are crucial for connecting to LangSmith and Azure OpenAI.\n",
        "\n",
        "| Variable | Purpose | Example Value |\n",
        "| :--- | :--- | :--- |\n",
        "| `LANGSMITH_API_KEY` | Authentication for LangSmith | `lsv2_sk_...` |\n",
        "| `LANGSMITH_TRACING` | Name of the LangSmith project for tracing | `true` |\n",
        "| `AZURE_OPENAI_ENDPOINT` | Your Azure OpenAI Service endpoint | `https://your-resource.openai.azure.com/` |\n",
        "| `AZURE_OPENAI_API_KEY` | Your Azure OpenAI API key | `abcdef123456...` |\n",
        "| `OPENAI_API_VERSION` | Azure OpenAI API version | `2024-02-01` |\n",
        "\n",
        "The Azure OpenAI deployment name used in this tutorial is **`gpt-4.1-mini`**, as specified in the requirements."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e54e1507",
      "metadata": {},
      "source": [
        "TO get LangSmith API key, sign up at [LangSmith](https://langsmith.langchain.com/signup).\n",
        "## Setup\n",
        "1. Navigate to settings from bottom left corner.\n",
        "2. Click on \"API Keys\" from the left menu.\n",
        "3. Click on \"Create New Key\" button to generate a new API key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "nbYpQjkYeX6w",
      "metadata": {
        "id": "nbYpQjkYeX6w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai langchain-core langsmith evaluate openai python-dotenv rouge_score --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "YEhUR-pjnqMd",
      "metadata": {
        "id": "YEhUR-pjnqMd"
      },
      "outputs": [],
      "source": [
        "# 1. Setup and Imports\n",
        "import os\n",
        "from langsmith import Client\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "#from evaluate import load\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OozwaPZVnr1a",
      "metadata": {
        "id": "OozwaPZVnr1a"
      },
      "outputs": [],
      "source": [
        "# --- Environment Variable Setup (Replace with your actual values or set them in your environment) ---\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"xxxxxxxxxxxxxxx\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "TJZer7DfoDcy",
      "metadata": {
        "id": "TJZer7DfoDcy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LangSmith Client Initialized.\n"
          ]
        }
      ],
      "source": [
        "# Initialize LangSmith Client\n",
        "client = Client()\n",
        "print(\"LangSmith Client Initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "vo2EgAHZW5QR",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo2EgAHZW5QR",
        "outputId": "61aa6724-0cb2-44e0-9ad7-e84dd397983d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AzureChatOpenAI Model Initialized with deployment: gpt-4.1-mini\n"
          ]
        }
      ],
      "source": [
        "# Initialize Azure OpenAI Model\n",
        "try:\n",
        "    llm = AzureChatOpenAI(\n",
        "        openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
        "        azure_deployment=\"gpt-4o-mini\",\n",
        "        temperature=0.7\n",
        "    )\n",
        "    print(\"AzureChatOpenAI Model Initialized with deployment: gpt-4.1-mini\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not initialize AzureChatOpenAI. Please ensure all environment variables are set correctly. Error: {e}\")\n",
        "    llm = None # Set to None if initialization fails\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7Nv6W91W5QS",
      "metadata": {
        "id": "c7Nv6W91W5QS"
      },
      "source": [
        "## 1. Prompt Registration (Pushing a Prompt)\n",
        "\n",
        "LangSmith allows you to register and version your prompts programmatically using the `client.push_prompt()` method. We will create a simple prompt for generating short, professional summaries of technical concepts.\n",
        "\n",
        "The prompt name we will use is **`technical-summary-generator`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "NaKrmmsaW5QS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaKrmmsaW5QS",
        "outputId": "9bd16ed8-cdc8-4aea-9b36-1d3a6451e76c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully registered prompt 'technical-summary-generator' (Version 1).\n",
            "View in LangSmith: https://smith.langchain.com/prompts/technical-summary-generator/4fe9f938?organizationId=e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073\n"
          ]
        }
      ],
      "source": [
        "# Define the initial prompt (Version 1)\n",
        "prompt_name = \"technical-summary-generator\"\n",
        "initial_template = (\n",
        "    \"You are a professional technical writer. \"\n",
        "    \"Your task is to write a concise, one-paragraph summary of the following technical concept: {concept}. \"\n",
        "    \"The summary must be easy to understand for a non-technical audience.\"\n",
        ")\n",
        "\n",
        "initial_prompt = ChatPromptTemplate.from_template(initial_template)\n",
        "\n",
        "# Push the initial prompt to LangSmith\n",
        "try:\n",
        "    url = client.push_prompt(prompt_name, object=initial_prompt)\n",
        "    print(f\"Successfully registered prompt '{prompt_name}' (Version 1).\")\n",
        "    print(f\"View in LangSmith: {url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error pushing prompt: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hpXPEfSYW5QS",
      "metadata": {
        "id": "hpXPEfSYW5QS"
      },
      "source": [
        "## 2. Prompt Modification (Pushing a New Version)\n",
        "\n",
        "To modify the prompt, we simply define a new version and use `client.push_prompt()` again with the same name. LangSmith automatically handles the versioning, creating a new commit for the change.\n",
        "\n",
        "**Modification**: We will add a constraint to include a real-world example in the summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "nac71c96W5QT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nac71c96W5QT",
        "outputId": "086be434-fa08-429e-deb2-f2e5898bc97e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully updated prompt 'technical-summary-generator' (Version 2).\n",
            "View in LangSmith: https://smith.langchain.com/prompts/technical-summary-generator/0b2d114c?organizationId=e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073\n"
          ]
        }
      ],
      "source": [
        "# Define the modified prompt (Version 2)\n",
        "modified_template = (\n",
        "    \"You are a professional technical writer. Your task is to write a concise, one-paragraph summary of the following technical concept: {concept}. \"\n",
        "    \"The summary must be easy to understand for a non-technical audience and **must include a simple, real-world example**.\"\n",
        ")\n",
        "\n",
        "modified_prompt = ChatPromptTemplate.from_template(modified_template)\n",
        "\n",
        "# Push the modified prompt to LangSmith\n",
        "try:\n",
        "    url = client.push_prompt(prompt_name, object=modified_prompt)\n",
        "    print(f\"Successfully updated prompt '{prompt_name}' (Version 2).\")\n",
        "    print(f\"View in LangSmith: {url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error pushing modified prompt: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yfnjjv3rW5QT",
      "metadata": {
        "id": "Yfnjjv3rW5QT"
      },
      "source": [
        "## 3. Loading the Prompt (Pulling a Prompt)\n",
        "\n",
        "We can load the latest version of the prompt using `client.pull_prompt()`. This ensures our application always uses the most up-to-date, tested prompt from the hub."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "9CWRAi9cW5QT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CWRAi9cW5QT",
        "outputId": "8939d8bf-f0fe-44f1-bdc8-22d5d2bf4fad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully pulled latest prompt: 'technical-summary-generator'\n",
            "\n",
            "--- Pulled Prompt Template ---\n",
            "You are a professional technical writer. Your task is to write a concise, one-paragraph summary of the following technical concept: {concept}. The summary must be easy to understand for a non-technical audience and **must include a simple, real-world example**.\n"
          ]
        }
      ],
      "source": [
        "# Pull the latest prompt from LangSmith\n",
        "try:\n",
        "    latest_prompt = client.pull_prompt(prompt_name)\n",
        "    print(f\"Successfully pulled latest prompt: '{prompt_name}'\")\n",
        "    print(\"\\n--- Pulled Prompt Template ---\")\n",
        "    print(latest_prompt.messages[0].prompt.template)\n",
        "except Exception as e:\n",
        "    print(f\"Error pulling prompt: {e}\")\n",
        "    latest_prompt = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jLtjt9kRW5QT",
      "metadata": {
        "id": "jLtjt9kRW5QT"
      },
      "source": [
        "## 4. Content Generation with Azure OpenAI\n",
        "\n",
        "Now we combine the loaded prompt with our `AzureChatOpenAI` model to create a simple LangChain Expression Language (LCEL) chain for content generation. The execution of this chain will automatically be traced and logged in LangSmith, linking the generated output back to the specific prompt version used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "sxYxoM84W5QT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxYxoM84W5QT",
        "outputId": "64b920c7-193d-4d25-91bd-87beae8a694c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary for: Quantum Computing...\n",
            "\n",
            "--- Generated Summary ---\n",
            "Quantum computing is an advanced type of computing that uses the principles of quantum mechanics to process information in ways that traditional computers cannot. Unlike classical computers, which use bits (0s and 1s) to store and manipulate data, quantum computers use qubits, which can represent both 0 and 1 simultaneously due to a property called superposition. This ability allows quantum computers to solve complex problems much faster than classical computers. For example, imagine trying to find the fastest route through a city with many roads; a classical computer would check each route one by one, while a quantum computer could evaluate multiple routes at the same time, significantly speeding up the process.\n",
            "\n",
            "Check LangSmith for the trace of this run!\n"
          ]
        }
      ],
      "source": [
        "if llm and latest_prompt:\n",
        "    # Create the LCEL chain: Prompt -> LLM -> Output Parser\n",
        "    chain = latest_prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Define the input concept\n",
        "    input_concept = \"Quantum Computing\"\n",
        "\n",
        "    print(f\"Generating summary for: {input_concept}...\")\n",
        "\n",
        "    # Invoke the chain\n",
        "    try:\n",
        "        response = chain.invoke({\"concept\": input_concept})\n",
        "        print(\"\\n--- Generated Summary ---\")\n",
        "        print(response)\n",
        "        print(\"\\nCheck LangSmith for the trace of this run!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during content generation: {e}\")\n",
        "        response = \"Generation Failed\"\n",
        "else:\n",
        "    response = \"Generation Skipped due to setup errors.\"\n",
        "    print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3BKTn9_Kmn7Q",
      "metadata": {
        "id": "3BKTn9_Kmn7Q"
      },
      "source": [
        "## 5. List, delete, and like prompts\n",
        "\n",
        "You can also list, delete, and like/unlike prompts using the list prompts, delete prompt, like prompt and unlike prompt methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "d869b013",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully registered prompt 'summary-generator' (Version 1).\n",
            "View in LangSmith: https://smith.langchain.com/prompts/summary-generator/ffb726a6?organizationId=e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073\n"
          ]
        }
      ],
      "source": [
        "# Define the initial prompt (Version 1)\n",
        "prompt_name = \"summary-generator\"\n",
        "initial_template = (\n",
        "    \"You are a professional Summary writer. \"\n",
        "    \"Your task is to write a concise, one-paragraph summary of the following technical concept: {concept}. \"\n",
        ")\n",
        "\n",
        "initial_prompt = ChatPromptTemplate.from_template(initial_template)\n",
        "\n",
        "# Push the initial prompt to LangSmith\n",
        "try:\n",
        "    url = client.push_prompt(prompt_name, object=initial_prompt)\n",
        "    print(f\"Successfully registered prompt '{prompt_name}' (Version 1).\")\n",
        "    print(f\"View in LangSmith: {url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error pushing prompt: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b8fb3130",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully registered prompt 'anshu-personal-prompt' (Version 1).\n",
            "View in LangSmith: https://smith.langchain.com/prompts/anshu-personal-prompt/4fe9f938?organizationId=e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073\n"
          ]
        }
      ],
      "source": [
        "# Define the initial prompt (Version 1)\n",
        "prompt_name = \"anshu-personal-prompt\"\n",
        "initial_template = (\n",
        "    \"You are a professional technical writer. \"\n",
        "    \"Your task is to write a concise, one-paragraph summary of the following technical concept: {concept}. \"\n",
        "    \"The summary must be easy to understand for a non-technical audience.\"\n",
        ")\n",
        "\n",
        "initial_prompt = ChatPromptTemplate.from_template(initial_template)\n",
        "\n",
        "# Push the initial prompt to LangSmith\n",
        "try:\n",
        "    url = client.push_prompt(prompt_name, object=initial_prompt)\n",
        "    print(f\"Successfully registered prompt '{prompt_name}' (Version 1).\")\n",
        "    print(f\"View in LangSmith: {url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error pushing prompt: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "o2APmHmfmx0M",
      "metadata": {
        "id": "o2APmHmfmx0M"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Prompt(repo_handle='anshu-personal-prompt', description='', readme='', id='355d1aff-b5f4-4ae1-b072-a4279066a819', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 32, 32, 470632), updated_at=datetime.datetime(2025, 11, 19, 10, 32, 34, 252930), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/anshu-personal-prompt', num_likes=0, num_downloads=0, num_views=0, liked_by_auth_user=False, last_commit_hash='4fe9f938e7e4a8e6e3a89e4d9f4fe00e0b3c917aeae2b6c401f181143201e4e3', num_commits=1, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='summary-generator', description='', readme='', id='70882c3c-579e-4ff9-88b0-e548380ffccb', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 32, 18, 870314), updated_at=datetime.datetime(2025, 11, 19, 10, 32, 20, 148229), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/summary-generator', num_likes=0, num_downloads=0, num_views=0, liked_by_auth_user=False, last_commit_hash='ffb726a621c3fb02f28b41b0ff6e2cb02f5b4161ec594c7d92c2520781e98848', num_commits=1, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='technical-summary-generator', description='', readme='', id='8adedbf4-97d7-4e8a-b28e-5c8c27e57305', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 24, 52, 909509), updated_at=datetime.datetime(2025, 11, 19, 10, 26, 28, 999727), is_public=False, is_archived=False, tags=['ChatPromptTemplate', 'ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/technical-summary-generator', num_likes=0, num_downloads=1, num_views=4, liked_by_auth_user=False, last_commit_hash='0b2d114c9a7e331ed2d7a82c530e6ea20a26ff23c155d31ee5c45a4831c493a9', num_commits=2, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='v3_generate_merge_schema', description='', readme='', id='510f504e-41a6-4733-acee-15885eb46694', tenant_id='9bdf2da0-bd79-499e-95f3-344a09bd0e02', created_at=datetime.datetime(2025, 4, 19, 14, 30, 33, 753816), updated_at=datetime.datetime(2025, 11, 19, 9, 48, 31, 528832), is_public=True, is_archived=False, tags=['ChatPromptTemplate', 'ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='innocifra', full_name='innocifra/v3_generate_merge_schema', num_likes=0, num_downloads=901, num_views=8, liked_by_auth_user=False, last_commit_hash='dad8983890c064b49489419166393e60de85b5b2b018c36952e65b62802f01e0', num_commits=2, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='v3_generate_tutor_questions', description='', readme='', id='3c172c7f-ea6f-4916-a8f1-0692ac6d54d5', tenant_id='9bdf2da0-bd79-499e-95f3-344a09bd0e02', created_at=datetime.datetime(2025, 4, 19, 14, 34, 26, 895237), updated_at=datetime.datetime(2025, 11, 19, 9, 48, 5, 304529), is_public=True, is_archived=False, tags=['ChatPromptTemplate', 'ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='innocifra', full_name='innocifra/v3_generate_tutor_questions', num_likes=0, num_downloads=19258, num_views=20, liked_by_auth_user=False, last_commit_hash='a95ffa1b32e8b45139e82d648185407c047b95a5c48dbe121617e2631b53f649', num_commits=3, original_repo_full_name=None, upstream_repo_full_name=None)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List all prompts in my workspace\n",
        "prompts = client.list_prompts()\n",
        "prompts.repos[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "564acf1a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Prompt(repo_handle='summary-generator', description='', readme='', id='70882c3c-579e-4ff9-88b0-e548380ffccb', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 32, 18, 870314), updated_at=datetime.datetime(2025, 11, 19, 10, 32, 20, 148229), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/summary-generator', num_likes=0, num_downloads=0, num_views=0, liked_by_auth_user=False, last_commit_hash='ffb726a621c3fb02f28b41b0ff6e2cb02f5b4161ec594c7d92c2520781e98848', num_commits=1, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='technical-summary-generator', description='', readme='', id='8adedbf4-97d7-4e8a-b28e-5c8c27e57305', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 24, 52, 909509), updated_at=datetime.datetime(2025, 11, 19, 10, 26, 28, 999727), is_public=False, is_archived=False, tags=['ChatPromptTemplate', 'ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/technical-summary-generator', num_likes=0, num_downloads=1, num_views=4, liked_by_auth_user=False, last_commit_hash='0b2d114c9a7e331ed2d7a82c530e6ea20a26ff23c155d31ee5c45a4831c493a9', num_commits=2, original_repo_full_name=None, upstream_repo_full_name=None)]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# List my private prompts that include \"joke\"\n",
        "prompts = client.list_prompts(query=\"summarize\", is_public=False)\n",
        "prompts.repos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e7909dd6",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Prompt(repo_handle='anshu-personal-prompt', description='', readme='', id='355d1aff-b5f4-4ae1-b072-a4279066a819', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 32, 32, 470632), updated_at=datetime.datetime(2025, 11, 19, 10, 32, 34, 252930), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/anshu-personal-prompt', num_likes=0, num_downloads=0, num_views=0, liked_by_auth_user=False, last_commit_hash='4fe9f938e7e4a8e6e3a89e4d9f4fe00e0b3c917aeae2b6c401f181143201e4e3', num_commits=1, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='summary-generator', description='', readme='', id='70882c3c-579e-4ff9-88b0-e548380ffccb', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 32, 18, 870314), updated_at=datetime.datetime(2025, 11, 19, 10, 32, 20, 148229), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/summary-generator', num_likes=0, num_downloads=0, num_views=0, liked_by_auth_user=False, last_commit_hash='ffb726a621c3fb02f28b41b0ff6e2cb02f5b4161ec594c7d92c2520781e98848', num_commits=1, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='technical-summary-generator', description='', readme='', id='8adedbf4-97d7-4e8a-b28e-5c8c27e57305', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 24, 52, 909509), updated_at=datetime.datetime(2025, 11, 19, 10, 26, 28, 999727), is_public=False, is_archived=False, tags=['ChatPromptTemplate', 'ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/technical-summary-generator', num_likes=0, num_downloads=1, num_views=4, liked_by_auth_user=False, last_commit_hash='0b2d114c9a7e331ed2d7a82c530e6ea20a26ff23c155d31ee5c45a4831c493a9', num_commits=2, original_repo_full_name=None, upstream_repo_full_name=None)]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts = client.list_prompts(is_public=False)\n",
        "prompts.repos[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "4955f96c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Delete a prompt\n",
        "prompt_name = \"anshu-personal-prompt\"\n",
        "client.delete_prompt(prompt_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "689b28e1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Prompt(repo_handle='summary-generator', description='', readme='', id='70882c3c-579e-4ff9-88b0-e548380ffccb', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 32, 18, 870314), updated_at=datetime.datetime(2025, 11, 19, 10, 32, 20, 148229), is_public=False, is_archived=False, tags=['ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/summary-generator', num_likes=0, num_downloads=0, num_views=0, liked_by_auth_user=False, last_commit_hash='ffb726a621c3fb02f28b41b0ff6e2cb02f5b4161ec594c7d92c2520781e98848', num_commits=1, original_repo_full_name=None, upstream_repo_full_name=None),\n",
              " Prompt(repo_handle='technical-summary-generator', description='', readme='', id='8adedbf4-97d7-4e8a-b28e-5c8c27e57305', tenant_id='e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073', created_at=datetime.datetime(2025, 11, 19, 10, 24, 52, 909509), updated_at=datetime.datetime(2025, 11, 19, 10, 26, 28, 999727), is_public=False, is_archived=False, tags=['ChatPromptTemplate', 'ChatPromptTemplate'], original_repo_id=None, upstream_repo_id=None, owner='anshupandey', full_name='anshupandey/technical-summary-generator', num_likes=0, num_downloads=1, num_views=4, liked_by_auth_user=False, last_commit_hash='0b2d114c9a7e331ed2d7a82c530e6ea20a26ff23c155d31ee5c45a4831c493a9', num_commits=2, original_repo_full_name=None, upstream_repo_full_name=None)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompts = client.list_prompts(is_public=False)\n",
        "prompts.repos[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc7e5f3f",
      "metadata": {},
      "outputs": [],
      "source": [
        "p1 = prompts.repos[0].repo_handle\n",
        "p2 = prompts.repos[1].repo_handle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "oLx-PcIunGWI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLx-PcIunGWI",
        "outputId": "aa484524-00b1-45e5-b801-c66824b621b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likes': 2}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Like a prompt\n",
        "client.like_prompt(\"efriis/my-first-prompt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "LWHpK0mKnIy2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWHpK0mKnIy2",
        "outputId": "95579bcb-d39f-48ed-9419-a08430fe4243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'likes': 1}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Unlike a prompt\n",
        "client.unlike_prompt(\"efriis/my-first-prompt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-8yDJbG_W5QT",
      "metadata": {
        "id": "-8yDJbG_W5QT"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This tutorial demonstrated a complete PromptOps workflow:\n",
        "\n",
        "1.  **Registration & Modification**: Using `client.push_prompt()` to version control prompts in LangSmith.\n",
        "2.  **Loading**: Using `client.pull_prompt()` to ensure the application uses the latest, approved version.\n",
        "3.  **Generation**: Integrating the prompt with `AzureChatOpenAI` via a LangChain LCEL chain, with automatic tracing to LangSmith.\n",
        "\n",
        "This workflow is the foundation for robust, and iterative development of LLM applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "KgLI7EpRgf-U",
      "metadata": {
        "id": "KgLI7EpRgf-U"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
