{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIXW11lkx4c5"
      },
      "source": [
        "# ðŸ§ª Comprehensive Prompt Evaluation with LangSmith\n",
        "\n",
        "This notebook provides a detailed tutorial on setting up and running a robust evaluation pipeline for LLM applications using **LangSmith**. We will use a **summarization task** as our use case and demonstrate three distinct types of evaluators: **Built-in Criteria**, **Formula-Based (BLEU/ROUGE)**, and a **Custom LLM-as-a-Judge**.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "Ensure the following environment variables are set. The LLM used is **Azure OpenAI** with the deployment name **`gpt-4.1-mini`**.\n",
        "\n",
        "| Variable | Purpose |\n",
        "| :--- | :--- |\n",
        "| `LANGSMITH_API_KEY` | Authentication for LangSmith |\n",
        "| `LANGSMITH_PROJECT` | Name of the LangSmith project for this experiment |\n",
        "| `AZURE_OPENAI_ENDPOINT` | Your Azure OpenAI Service endpoint |\n",
        "| `AZURE_OPENAI_API_KEY` | Your Azure OpenAI API key |\n",
        "| `OPENAI_API_VERSION` | Azure OpenAI API version |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkdkKHdgzPMh",
        "outputId": "2fcd83fc-758d-458e-e675-3abb69ca3f37"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -zure-cognitiveservices-speech (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\anshu pandey\\appdata\\roaming\\python\\python310\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-openai langchain-core langsmith evaluate openai python-dotenv rouge_score openevals --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tHg7wkSNzQsE"
      },
      "outputs": [],
      "source": [
        "# 1. Setup and Imports\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from langsmith import Client, evaluate\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from openevals.llm import create_llm_as_judge\n",
        "from openevals.prompts import CONCISENESS_PROMPT\n",
        "from evaluate import load as load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VoltJJFuzS2o"
      },
      "outputs": [],
      "source": [
        "# --- Environment Variable Setup (Replace with your actual values or set them in your environment) ---\n",
        "os.environ[\"LANGSMITH_API_KEY\"] = \"xxxxxxxxxxxxxxxxxxxxx\"\n",
        "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKXw_rPmy40N",
        "outputId": "811726ec-9fa7-46fa-bbac-5f1304c6d8a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clients Initialized: LangSmith Client and AzureChatOpenAI (gpt-4.1-mini)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize Clients\n",
        "client = Client()\n",
        "llm = AzureChatOpenAI(\n",
        "    openai_api_version=os.environ[\"OPENAI_API_VERSION\"],\n",
        "    azure_deployment=\"gpt-4o-mini\",\n",
        "    temperature=0.0 # Use low temperature for deterministic evaluation\n",
        ")\n",
        "\n",
        "print(\"Clients Initialized: LangSmith Client and AzureChatOpenAI (gpt-4.1-mini)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AemThga3y0Ky"
      },
      "source": [
        "## 2. Dataset Creation and Upload\n",
        "\n",
        "We define a dataset for a summarization task. Each example contains the technical article (`input`) and a high-quality, human-written summary (`reference`).\n",
        "\n",
        "### Dataset Definition (10 Samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zbWScMYyq67",
        "outputId": "211b5cbc-6f9b-4a8e-c66a-f75dc5abd483"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset 'Technical Summarization Evaluation 2' uploaded successfully with 10 examples.\n"
          ]
        }
      ],
      "source": [
        "dataset_name = \"Technical Summarization Evaluation 2\"\n",
        "\n",
        "raw_dataset = [\n",
        "    {\"input\": \"The core principle of blockchain technology is the decentralized, distributed ledger. This ledger records transactions across many computers so that the record cannot be altered retroactively without the alteration of all subsequent blocks and the consensus of the network. This makes it highly secure and transparent.\", \"reference\": \"Blockchain is a secure, transparent record of transactions that is shared across many computers, making it impossible to change past entries without network agreement.\", \"concept\": \"Blockchain\"},\n",
        "    {\"input\": \"Quantum computing utilizes quantum phenomena such as superposition and entanglement to perform computations. A qubit, the basic unit of quantum information, can exist in a combination of states simultaneously, unlike a classical bit which is strictly 0 or 1. This allows quantum computers to solve certain complex problems exponentially faster.\", \"reference\": \"Quantum computing uses special physics like superposition to make powerful computers. Its basic unit, the qubit, can be both 0 and 1 at once, enabling it to solve very hard problems much quicker than normal computers.\", \"concept\": \"Quantum Computing\"},\n",
        "    {\"input\": \"The transformer architecture, introduced in the paper \\\"Attention Is All You Need,\\\" is the foundational model for modern large language models (LLMs). It relies entirely on a mechanism called self-attention, which weighs the importance of different words in the input sequence to better understand context, eliminating the need for recurrent or convolutional layers.\", \"reference\": \"The transformer is the key technology behind modern AI language models. It uses a self-attention mechanism to figure out which words in a sentence are most important for context, which is a major improvement over older models.\", \"concept\": \"Transformer Architecture\"},\n",
        "    {\"input\": \"Deep learning is a subset of machine learning that uses artificial neural networks with multiple layers (hence \\\"deep\\\") to analyze data. These networks are capable of learning from unstructured data, such as images, text, and sound, by progressively extracting higher-level features from the raw input.\", \"reference\": \"Deep learning is a type of machine learning that uses multi-layered networks to learn complex patterns from data like images and text, allowing it to automatically identify high-level features.\", \"concept\": \"Deep Learning\"},\n",
        "    {\"input\": \"A microservice architecture is a method of developing software applications as a suite of small, independent services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. This contrasts with a monolithic architecture where all components are tightly coupled.\", \"reference\": \"Microservices are a way to build software using many small, separate programs that talk to each other, making the application easier to develop, deploy, and scale compared to one large, single program.\", \"concept\": \"Microservices\"},\n",
        "    {\"input\": \"The CAP theorem states that a distributed data store can only provide two of the three guarantees: Consistency, Availability, and Partition tolerance. Most modern distributed systems must choose which two properties to prioritize based on their specific needs.\", \"reference\": \"The CAP theorem explains that networked databases can only guarantee two out of three things: that all users see the same data (Consistency), that the system is always running (Availability), or that it works even if parts of the network fail (Partition tolerance).\", \"concept\": \"CAP Theorem\"},\n",
        "    {\"input\": \"DevOps is a set of practices that combines software development (Dev) and IT operations (Ops). It aims to shorten the systems development life cycle and provide continuous delivery with high software quality. Key practices include continuous integration and continuous delivery (CI/CD).\", \"reference\": \"DevOps is a way of working that merges software development and IT operations to speed up the process of building and releasing high-quality software, often using automated tools like CI/CD.\", \"concept\": \"DevOps\"},\n",
        "    {\"input\": \"Containerization, typically implemented using Docker, is the packaging of software code with all its dependencies so that it can run reliably on any computing environment. This isolates the application from the host system, ensuring consistency from development to production.\", \"reference\": \"Containerization (like Docker) bundles an application with everything it needs to run, ensuring it works the same way everywhere, from a developer's laptop to a production server.\", \"concept\": \"Containerization\"},\n",
        "    {\"input\": \"Natural Language Processing (NLP) is a field of artificial intelligence that gives computers the ability to understand human language. This includes tasks like text translation, sentiment analysis, and speech recognition, often relying on complex statistical models and deep learning.\", \"reference\": \"NLP is the branch of AI that teaches computers to understand human language. It powers applications like translation and sentiment analysis by using advanced statistical and deep learning models.\", \"concept\": \"NLP\"},\n",
        "    {\"input\": \"The concept of \\\"serverless computing\\\" allows developers to build and run applications without having to manage the underlying infrastructure. The cloud provider dynamically manages the allocation and provisioning of servers, and the user is typically billed only for the compute time consumed.\", \"reference\": \"Serverless computing lets developers run code without worrying about servers. The cloud provider handles all the infrastructure, and you only pay for the time your code is actually running.\", \"concept\": \"Serverless Computing\"}\n",
        "]\n",
        "\n",
        "# Upload the dataset to LangSmith\n",
        "try:\n",
        "    dataset = client.create_dataset(dataset_name, description=\"Dataset for evaluating technical summarization prompt.\")\n",
        "    for example in raw_dataset:\n",
        "        client.create_example(\n",
        "            dataset_id=dataset.id,\n",
        "            inputs={\"input\": example[\"input\"]},\n",
        "            outputs={\"reference\": example[\"reference\"]}\n",
        "        )\n",
        "    print(f\"Dataset '{dataset_name}' uploaded successfully with {len(raw_dataset)} examples.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading dataset: {e}\")\n",
        "    dataset = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwKto56Oyr3L"
      },
      "source": [
        "## 3. Define the Application Chain\n",
        "\n",
        "This is the application we are testing: a simple chain that takes a technical article and produces a summary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGdAsXCCyZgv",
        "outputId": "f1c4da6f-4cc8-41b2-8185-d107d0982608"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Application Chain Defined.\n"
          ]
        }
      ],
      "source": [
        "# Define the Summarization Prompt\n",
        "summarization_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert technical writer. Your task is to write a concise, one-paragraph summary of the following technical text for a non-technical audience.\"),\n",
        "    (\"user\", \"{input}\")\n",
        "])\n",
        "\n",
        "# Define the Application Chain\n",
        "summarization_chain = summarization_prompt | llm | StrOutputParser()\n",
        "\n",
        "print(\"Application Chain Defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1YxSnc1yZPk"
      },
      "source": [
        "\n",
        "## 4. Define Evaluators\n",
        "\n",
        "We will define three types of evaluators using the latest recommended methods:\n",
        "\n",
        "1. Built-in LLM-as-a-Judge (via openevals): Using `create_llm_as_judge` with a pre-built prompt for a common criterion like Conciseness.\n",
        "\n",
        "2. Formula-Based (Custom Code Evaluator): A standard Python function for `ROUGE-L` and `BLEU`.\n",
        "\n",
        "3. Custom LLM-as-a-Judge (via openevals): Using `create_llm_as_judge` with a custom prompt for a specific criterion like Clarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an expert data labeler evaluating model outputs for conciseness. Your task is to assign a score based on the following rubric:\n",
            "\n",
            "<Rubric>\n",
            "  A perfectly concise answer:\n",
            "  - Contains only the exact information requested.\n",
            "  - Uses the minimum number of words necessary to convey the complete answer.\n",
            "  - Omits pleasantries, hedging language, and unnecessary context.\n",
            "  - Excludes meta-commentary about the answer or the model's capabilities.\n",
            "  - Avoids redundant information or restatements.\n",
            "  - Does not include explanations unless explicitly requested.\n",
            "\n",
            "  When scoring, you should deduct points for:\n",
            "  - Introductory phrases like \"I believe,\" \"I think,\" or \"The answer is.\"\n",
            "  - Hedging language like \"probably,\" \"likely,\" or \"as far as I know.\"\n",
            "  - Unnecessary context or background information.\n",
            "  - Explanations when not requested.\n",
            "  - Follow-up questions or offers for more information.\n",
            "  - Redundant information or restatements.\n",
            "  - Polite phrases like \"hope this helps\" or \"let me know if you need anything else.\"\n",
            "</Rubric>\n",
            "\n",
            "<Instructions>\n",
            "  - Carefully read the input and output.\n",
            "  - Check for any unnecessary elements, particularly those mentioned in the <Rubric> above.\n",
            "  - The score should reflect how close the response comes to containing only the essential information requested based on the rubric above.\n",
            "</Instructions>\n",
            "\n",
            "<Reminder>\n",
            "  The goal is to reward responses that provide complete answers with absolutely no extraneous information.\n",
            "</Reminder>\n",
            "\n",
            "<input>\n",
            "{inputs}\n",
            "</input>\n",
            "\n",
            "<output>\n",
            "{outputs}\n",
            "</output>\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(CONCISENESS_PROMPT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FlyIXdqu8ez3"
      },
      "outputs": [],
      "source": [
        "# --- A. Built-in LLM-as-a-Judge (Conciseness) ---\n",
        "# Uses the openevals package for a pre-built LLM-as-a-Judge\n",
        "conciseness_evaluator = create_llm_as_judge(\n",
        "    prompt=CONCISENESS_PROMPT,\n",
        "    feedback_key=\"Conciseness\",\n",
        "    model=\"azure_openai:gpt-4o-mini\", # Using the model name as expected by openevals\n",
        "    continuous=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Qbnyb6AVWW",
        "outputId": "3a68380b-8e32-48e6-8288-8912223d47f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'key': 'Conciseness',\n",
              " 'score': 0.5,\n",
              " 'comment': \"The output provides a clear explanation of blockchain technology, but it includes unnecessary context and a restatement of points about security and transparency. It does not follow the rubric for a perfectly concise answer by omitting extraneous details, such as mentioning 'digital ledger' and explaining the consensus mechanism, which were not explicitly requested. Additionally, it does not include any hedging language or polite phrases. Thus, the score should be: 0.5.\",\n",
              " 'metadata': None}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test\n",
        "conciseness_evaluator(inputs=raw_dataset[0]['input'],outputs=summarization_chain.invoke(raw_dataset[0]['input']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yw_OA8hOAU8G"
      },
      "outputs": [],
      "source": [
        "# --- B. Formula-Based Evaluator (Custom Code Evaluator) ---\n",
        "# This function calculates ROUGE-L and BLEU scores using the 'evaluate' library.\n",
        "def formula_based_evaluator(outputs: dict, reference_outputs: dict):\n",
        "    prediction = outputs\n",
        "    reference = reference_outputs\n",
        "\n",
        "    # Load metrics\n",
        "    rouge = load_metric(\"rouge\")\n",
        "    bleu = load_metric(\"bleu\")\n",
        "\n",
        "    # Compute ROUGE-L\n",
        "    rouge_results = rouge.compute(predictions=[prediction['output']], references=[reference['reference']])\n",
        "\n",
        "    # Compute BLEU\n",
        "    bleu_results = bleu.compute(predictions=[prediction['output']], references=[reference['reference']])\n",
        "\n",
        "    return [{\"key\":\"ROUGE-L\",\"score\":float(rouge_results[\"rougeL\"])},{\"key\":\"BLEU\",\"score\":bleu_results[\"bleu\"]},]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4WjuvoOBr5t",
        "outputId": "28465d74-f323-4105-c9dc-b41a7f72ca4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'key': 'ROUGE-L', 'value': 0.3055555555555555},\n",
              " {'key': 'BLEU', 'value': 0.0}]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "formula_based_evaluator(outputs={'output':summarization_chain.invoke(raw_dataset[0]['input'])},\n",
        "                        reference_outputs={'reference':raw_dataset[0]['reference']},)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT7b1CTAATLe",
        "outputId": "e9ad435c-26ac-429a-a1be-1374eff4f540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All three evaluators defined using the latest best practices.\n"
          ]
        }
      ],
      "source": [
        "# --- C. Custom LLM-as-a-Judge Evaluator (Clarity) ---\n",
        "# We define a custom prompt for clarity and use create_llm_as_judge.\n",
        "CLARITY_PROMPT = \"\"\"\n",
        "You are an expert content evaluator. Your task is to rate the clarity of a technical summary for a non-technical audience.\n",
        "\n",
        "**Criteria:** Clarity for Non-Technical Audience\n",
        "**Score:** 1-5 (5 is excellent, 1 is poor)\n",
        "**Reasoning:** Explain your score.\n",
        "\n",
        "**Input (Original Text):** {inputs}\n",
        "**Reference (Ground Truth Summary):** {reference_outputs}\n",
        "**Prediction (Model Output):** {outputs}\n",
        "\n",
        "Respond ONLY with a JSON object containing the keys 'score' (integer 1-5) and 'reasoning' (string).\n",
        "\"\"\"\n",
        "\n",
        "clarity_evaluator = create_llm_as_judge(\n",
        "    prompt=CLARITY_PROMPT,\n",
        "    feedback_key=\"Clarity_Score\",\n",
        "    model=\"azure_openai:gpt-4o-mini\", # Using the model name as expected by openevals\n",
        "    continuous=True\n",
        ")\n",
        "\n",
        "print(\"All three evaluators defined using the latest best practices.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm-z38skEENB",
        "outputId": "9d3e82b1-19b9-43ef-9748-e8d1556e9064"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'key': 'Clarity_Score',\n",
              " 'score': 5,\n",
              " 'comment': 'The predicted summary successfully explains the core concepts of blockchain technology in simple terms that a non-technical audience can easily understand. It highlights the shared digital ledger, the importance of network consensus for changes, and the security and transparency aspects in a clear manner. The language used is accessible, making the technical details comprehensible. Thus, the score should be: 5.',\n",
              " 'metadata': None}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test\n",
        "clarity_evaluator(inputs=raw_dataset[0]['input'],outputs=summarization_chain.invoke(raw_dataset[0]['input']),reference_outputs=raw_dataset[0]['reference'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TunEgNxybvL"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "## 5. Run the Evaluation Experiment\n",
        "\n",
        "The recommended function for running evaluations is `langsmith.evaluate()`. This is a simpler, top-level function that handles the execution against the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538,
          "referenced_widgets": [
            "4b831a7805c244efa120f080aaaa117c",
            "69e66138df7242f0a7feb940bcb3fccb",
            "e6aca9e14c1942e099d3e033e6901a62",
            "99885e51e6814ed185db55f2e3f481ac",
            "a16766da5bfc428888c999a4bc9f2943",
            "09543b8735344521ba3bf951e4e9b5d3",
            "aa79bd9d4cb44d92ae89a658f37112cd",
            "e001b669e4024833a23c6a38719d1e71",
            "851122b23025419ca2e0713dbf110fda",
            "102ba5ffe3bf4ffc938d1c73177598fc",
            "211183bcbc0a4e1682f0f656e1e02de7"
          ]
        },
        "id": "pizlwCUV9BzS",
        "outputId": "4195ebf1-df93-4310-998e-3c369a2c13ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting experiment 'Summarization-Prompt-V1-Final' on dataset 'Technical Summarization Evaluation 2'...\n",
            "View the evaluation results for experiment: 'Summarization-Prompt-V1-Final-be60f1c9' at:\n",
            "https://smith.langchain.com/o/e5ffb10d-d7d5-5a52-9eb0-1e8ca168f073/datasets/627a00ac-a3f0-491c-9d77-e704a5d7ea2d/compare?selectedSessions=5e5b0f4b-9d25-415a-9df8-2b8a0bcabd51\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f51fadfa0e324889b413c70032d70d8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.3956043956043956\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.0740127859867281\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.4415584415584416\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.09684433213089316\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.2469135802469136\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.07956125944558465\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.3908045977011494\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.13537645428566158\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.4\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.17348561248764943\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.23913043478260868\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.0\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.30434782608695654\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.08960502892905796\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.3716814159292036\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.14299316957884914\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.34951456310679613\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.07908785331520057\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.3098591549295775\n",
            "WARNING:langsmith.evaluation.evaluator:Numeric values should be provided in the 'score' field, not 'value'. Got: 0.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Experiment completed. Check LangSmith for detailed results.\n"
          ]
        }
      ],
      "source": [
        "experiment_name = \"Summarization-Prompt-V1-Final\"\n",
        "\n",
        "if dataset:\n",
        "    # Define the list of evaluators to run\n",
        "    evaluators = [\n",
        "        conciseness_evaluator,\n",
        "        formula_based_evaluator,\n",
        "       clarity_evaluator\n",
        "    ]\n",
        "\n",
        "    print(f\"Starting experiment '{experiment_name}' on dataset '{dataset_name}'...\")\n",
        "\n",
        "    # Run the experiment using the top-level evaluate function\n",
        "    try:\n",
        "        run_results = evaluate(\n",
        "            summarization_chain.invoke, # Pass the invoke method of the chain\n",
        "            data=dataset_name, # Pass the dataset name\n",
        "            evaluators=evaluators,\n",
        "            experiment_prefix=experiment_name,\n",
        "            # Note: The LLM is passed to the evaluators that need it via the 'model' parameter in create_llm_as_judge\n",
        "        )\n",
        "        print(\"\\nExperiment completed. Check LangSmith for detailed results.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error running experiment: {e}\")\n",
        "        run_results = None\n",
        "else:\n",
        "    print(\"Cannot run experiment: Dataset was not successfully uploaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbQGsTZ8yDkK"
      },
      "source": [
        "## 6. Analysis and Interpretation\n",
        "\n",
        "We can retrieve the results from LangSmith and display them in a DataFrame for local analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4ke7_7AuObaZ",
        "outputId": "b765cb24-f61d-4a97-b8c5-41880359713f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs.input</th>\n",
              "      <th>outputs.output</th>\n",
              "      <th>error</th>\n",
              "      <th>reference.reference</th>\n",
              "      <th>feedback.Conciseness</th>\n",
              "      <th>feedback.ROUGE-L</th>\n",
              "      <th>feedback.BLEU</th>\n",
              "      <th>feedback.Clarity_Score</th>\n",
              "      <th>execution_time</th>\n",
              "      <th>example_id</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The concept of \"serverless computing\" allows d...</td>\n",
              "      <td>Serverless computing is a modern approach that...</td>\n",
              "      <td>None</td>\n",
              "      <td>Serverless computing lets developers run code ...</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.3956043956043956</td>\n",
              "      <td>0.0740127859867281</td>\n",
              "      <td>4</td>\n",
              "      <td>6.848437</td>\n",
              "      <td>b5b1852c-752c-4479-9e16-3860e1cd94b5</td>\n",
              "      <td>019a9f8b-c6da-745e-aae6-28b323055d88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Natural Language Processing (NLP) is a field o...</td>\n",
              "      <td>Natural Language Processing (NLP) is a branch ...</td>\n",
              "      <td>None</td>\n",
              "      <td>NLP is the branch of AI that teaches computers...</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.4415584415584416</td>\n",
              "      <td>0.09684433213089316</td>\n",
              "      <td>4</td>\n",
              "      <td>4.761863</td>\n",
              "      <td>1acb0e13-514f-4985-a7bd-0799bf77b163</td>\n",
              "      <td>019a9f8c-04cb-740b-aea6-fa34813a78b2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Containerization, typically implemented using ...</td>\n",
              "      <td>Containerization is a method of packaging soft...</td>\n",
              "      <td>None</td>\n",
              "      <td>Containerization (like Docker) bundles an appl...</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.2469135802469136</td>\n",
              "      <td>0.07956125944558465</td>\n",
              "      <td>4</td>\n",
              "      <td>5.492313</td>\n",
              "      <td>08ee4279-364a-459d-a823-ad7e7a2847cb</td>\n",
              "      <td>019a9f8c-3679-716f-927e-203b63afcd7e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DevOps is a set of practices that combines sof...</td>\n",
              "      <td>DevOps is a modern approach that brings togeth...</td>\n",
              "      <td>None</td>\n",
              "      <td>DevOps is a way of working that merges softwar...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.3908045977011494</td>\n",
              "      <td>0.13537645428566158</td>\n",
              "      <td>5</td>\n",
              "      <td>4.714852</td>\n",
              "      <td>c5c70600-71b2-4e75-8df1-85fc6863a1d9</td>\n",
              "      <td>019a9f8c-7655-7429-a4f0-e4a59e16deec</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The CAP theorem states that a distributed data...</td>\n",
              "      <td>The CAP theorem explains that in a system wher...</td>\n",
              "      <td>None</td>\n",
              "      <td>The CAP theorem explains that networked databa...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.17348561248764943</td>\n",
              "      <td>4</td>\n",
              "      <td>6.798483</td>\n",
              "      <td>7133b2e7-a4db-4a40-870e-c1380df166ce</td>\n",
              "      <td>019a9f8c-b5ea-757a-bb2a-fb36cee76256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A microservice architecture is a method of dev...</td>\n",
              "      <td>A microservice architecture is a way of buildi...</td>\n",
              "      <td>None</td>\n",
              "      <td>Microservices are a way to build software usin...</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.23913043478260868</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>5.667856</td>\n",
              "      <td>e8262917-cfe5-455a-b413-415461f16742</td>\n",
              "      <td>019a9f8c-f970-7170-af5a-37f1c38c3ae7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Deep learning is a subset of machine learning ...</td>\n",
              "      <td>Deep learning is a type of advanced technology...</td>\n",
              "      <td>None</td>\n",
              "      <td>Deep learning is a type of machine learning th...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.30434782608695654</td>\n",
              "      <td>0.08960502892905796</td>\n",
              "      <td>4</td>\n",
              "      <td>5.186891</td>\n",
              "      <td>f870b13b-91e9-40b6-8ed1-a5b9ddf47cce</td>\n",
              "      <td>019a9f8d-3127-7251-a562-8a7739909947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The transformer architecture, introduced in th...</td>\n",
              "      <td>The transformer architecture, created in the i...</td>\n",
              "      <td>None</td>\n",
              "      <td>The transformer is the key technology behind m...</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.3716814159292036</td>\n",
              "      <td>0.14299316957884914</td>\n",
              "      <td>4</td>\n",
              "      <td>7.915816</td>\n",
              "      <td>9fd43471-2858-47b7-a1e3-2af420958d84</td>\n",
              "      <td>019a9f8d-6659-7571-80e4-1d6ec8b99f5f</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Quantum computing utilizes quantum phenomena s...</td>\n",
              "      <td>Quantum computing is a new technology that use...</td>\n",
              "      <td>None</td>\n",
              "      <td>Quantum computing uses special physics like su...</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.34951456310679613</td>\n",
              "      <td>0.07908785331520057</td>\n",
              "      <td>4</td>\n",
              "      <td>7.135723</td>\n",
              "      <td>da222028-608b-4986-852f-1c37c65ba0e1</td>\n",
              "      <td>019a9f8d-ab98-75cf-99f4-bfa6fa0fa113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The core principle of blockchain technology is...</td>\n",
              "      <td>Blockchain technology operates on a system whe...</td>\n",
              "      <td>None</td>\n",
              "      <td>Blockchain is a secure, transparent record of ...</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.3098591549295775</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>4.339017</td>\n",
              "      <td>5bddd936-6515-4d2a-a17c-0f4b27f4bff2</td>\n",
              "      <td>019a9f8d-eb51-7247-be07-4476cea2e4ad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        inputs.input  \\\n",
              "0  The concept of \"serverless computing\" allows d...   \n",
              "1  Natural Language Processing (NLP) is a field o...   \n",
              "2  Containerization, typically implemented using ...   \n",
              "3  DevOps is a set of practices that combines sof...   \n",
              "4  The CAP theorem states that a distributed data...   \n",
              "5  A microservice architecture is a method of dev...   \n",
              "6  Deep learning is a subset of machine learning ...   \n",
              "7  The transformer architecture, introduced in th...   \n",
              "8  Quantum computing utilizes quantum phenomena s...   \n",
              "9  The core principle of blockchain technology is...   \n",
              "\n",
              "                                      outputs.output error  \\\n",
              "0  Serverless computing is a modern approach that...  None   \n",
              "1  Natural Language Processing (NLP) is a branch ...  None   \n",
              "2  Containerization is a method of packaging soft...  None   \n",
              "3  DevOps is a modern approach that brings togeth...  None   \n",
              "4  The CAP theorem explains that in a system wher...  None   \n",
              "5  A microservice architecture is a way of buildi...  None   \n",
              "6  Deep learning is a type of advanced technology...  None   \n",
              "7  The transformer architecture, created in the i...  None   \n",
              "8  Quantum computing is a new technology that use...  None   \n",
              "9  Blockchain technology operates on a system whe...  None   \n",
              "\n",
              "                                 reference.reference  feedback.Conciseness  \\\n",
              "0  Serverless computing lets developers run code ...                  0.30   \n",
              "1  NLP is the branch of AI that teaches computers...                  0.30   \n",
              "2  Containerization (like Docker) bundles an appl...                  0.60   \n",
              "3  DevOps is a way of working that merges softwar...                  0.20   \n",
              "4  The CAP theorem explains that networked databa...                  0.20   \n",
              "5  Microservices are a way to build software usin...                  0.25   \n",
              "6  Deep learning is a type of machine learning th...                  0.20   \n",
              "7  The transformer is the key technology behind m...                  0.20   \n",
              "8  Quantum computing uses special physics like su...                  0.30   \n",
              "9  Blockchain is a secure, transparent record of ...                  0.40   \n",
              "\n",
              "      feedback.ROUGE-L        feedback.BLEU  feedback.Clarity_Score  \\\n",
              "0   0.3956043956043956   0.0740127859867281                       4   \n",
              "1   0.4415584415584416  0.09684433213089316                       4   \n",
              "2   0.2469135802469136  0.07956125944558465                       4   \n",
              "3   0.3908045977011494  0.13537645428566158                       5   \n",
              "4                  0.4  0.17348561248764943                       4   \n",
              "5  0.23913043478260868                  0.0                       4   \n",
              "6  0.30434782608695654  0.08960502892905796                       4   \n",
              "7   0.3716814159292036  0.14299316957884914                       4   \n",
              "8  0.34951456310679613  0.07908785331520057                       4   \n",
              "9   0.3098591549295775                  0.0                       4   \n",
              "\n",
              "   execution_time                            example_id  \\\n",
              "0        6.848437  b5b1852c-752c-4479-9e16-3860e1cd94b5   \n",
              "1        4.761863  1acb0e13-514f-4985-a7bd-0799bf77b163   \n",
              "2        5.492313  08ee4279-364a-459d-a823-ad7e7a2847cb   \n",
              "3        4.714852  c5c70600-71b2-4e75-8df1-85fc6863a1d9   \n",
              "4        6.798483  7133b2e7-a4db-4a40-870e-c1380df166ce   \n",
              "5        5.667856  e8262917-cfe5-455a-b413-415461f16742   \n",
              "6        5.186891  f870b13b-91e9-40b6-8ed1-a5b9ddf47cce   \n",
              "7        7.915816  9fd43471-2858-47b7-a1e3-2af420958d84   \n",
              "8        7.135723  da222028-608b-4986-852f-1c37c65ba0e1   \n",
              "9        4.339017  5bddd936-6515-4d2a-a17c-0f4b27f4bff2   \n",
              "\n",
              "                                     id  \n",
              "0  019a9f8b-c6da-745e-aae6-28b323055d88  \n",
              "1  019a9f8c-04cb-740b-aea6-fa34813a78b2  \n",
              "2  019a9f8c-3679-716f-927e-203b63afcd7e  \n",
              "3  019a9f8c-7655-7429-a4f0-e4a59e16deec  \n",
              "4  019a9f8c-b5ea-757a-bb2a-fb36cee76256  \n",
              "5  019a9f8c-f970-7170-af5a-37f1c38c3ae7  \n",
              "6  019a9f8d-3127-7251-a562-8a7739909947  \n",
              "7  019a9f8d-6659-7571-80e4-1d6ec8b99f5f  \n",
              "8  019a9f8d-ab98-75cf-99f4-bfa6fa0fa113  \n",
              "9  019a9f8d-eb51-7247-be07-4476cea2e4ad  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "run_results.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Nvidia's CEO, Jensen Huang, recently addressed concerns about a potential AI bubble, highlighting the company's strong third-quarter earnings and optimistic fourth-quarter forecast, which eased investor worries. Despite previous slow sales, Nvidia's growth is driven by high demand for its chips across various sectors, including cloud computing and robotics. Huang emphasized the company's widespread presence in the tech industry and its significant bookings of $500 billion for advanced chips through 2026. Following this positive news, Nvidia's stock rose by 5%, adding $220 billion to its market value, even as the overall market has seen a decline.\""
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summarization_chain.invoke({'input':\"\"\"\n",
        "Reuters) -Nvidia CEO Jensen Huang on Wednesday shrugged off concerns about an AI bubble as the company surprised Wall Street with accelerating growth after several quarters of slowing sales.\n",
        "\n",
        "The chipmaker's stellar third-quarter earnings and fourth-quarter forecast calmed, at least temporarily, investor nerves over concerns an AI boom has outrun fundamentals. Global markets have looked to the chip designer to determine whether investing billions of dollars in AI infrastructure expansion has resulted in an AI bubble.\n",
        "\n",
        "\"There's been a lot of talk about an AI bubble. From our vantage point, we see something very different,\" CEO Jensen Huang said on a call with analysts, where he touted how much cloud companies wanted Nvidia chips.\n",
        "\n",
        "\"We're in every cloud. The reason why developers love us is because we're literally everywhere,\" he said. \"We're everywhere from cloud to on-premise to robotic systems, edge devices, PCs, you name it. One architecture. Things just work. It's incredible.\"\n",
        "\n",
        "He reiterated a forecast from last month that the company had $500 billion in bookings for its advanced chips through 2026.\n",
        "\n",
        "Shares of the AI market bellwether jumped 5% in extended trading, setting up the company to add $220 billion in market value. Ahead of the results, doubts had pushed Nvidia's shares down nearly 8% in November, after a surge of 1,200% in the past three years.\n",
        "\n",
        "The broader market has declined almost 3% this month.\n",
        "                            \"\"\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utl88sm6x2LA",
        "outputId": "1045564a-a9ae-451b-c7a6-ea9c33fa8abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Evaluation Results Summary (First 5 Samples) ---\n",
            "| Input Text                                                                                                                                                                                                                                                                                            | Generated Summary                                                                                                                                                                                                                                                                                                                                                                                                     |   LLM Judge: Conciseness |   ROUGE-L |      BLEU |   LLM Judge: Clarity Score |\n",
            "|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------:|----------:|----------:|---------------------------:|\n",
            "| The concept of \"serverless computing\" allows developers to build and run applications without having to manage the underlying infrastructure. The cloud provider dynamically manages the allocation and provisioning of servers, and the user is typically billed only for the compute time consumed. | Serverless computing is a way for developers to create and run applications without worrying about managing the physical computers or servers behind them. Instead, a cloud service automatically handles all the technical details of running the app, and users only pay for the actual time their application is working. This makes it easier and often more cost-effective to build and maintain software.       |                      0.5 |  0.413043 | 0.0819086 |                          5 |\n",
            "| Natural Language Processing (NLP) is a field of artificial intelligence that gives computers the ability to understand human language. This includes tasks like text translation, sentiment analysis, and speech recognition, often relying on complex statistical models and deep learning.          | Natural Language Processing, or NLP, is a technology that helps computers understand and work with human language. It enables machines to do things like translate languages, recognize emotions in text, and understand spoken words, using advanced methods to make sense of the way we communicate.                                                                                                                |                      0.4 |  0.324324 | 0.0686129 |                          5 |\n",
            "| Containerization, typically implemented using Docker, is the packaging of software code with all its dependencies so that it can run reliably on any computing environment. This isolates the application from the host system, ensuring consistency from development to production.                  | Containerization is a method of packaging software along with everything it needs to run, so it works the same way on any computer. This approach keeps the software separate from the underlying system, making sure it behaves consistently from the time it's created to when it's used in real-world situations.                                                                                                  |                      0.8 |  0.37037  | 0.183682  |                          5 |\n",
            "| DevOps is a set of practices that combines software development (Dev) and IT operations (Ops). It aims to shorten the systems development life cycle and provide continuous delivery with high software quality. Key practices include continuous integration and continuous delivery (CI/CD).        | DevOps is a way of working that brings together software creation and IT management to make developing and updating software faster and more reliable. It focuses on quickly building, testing, and delivering software so users get improvements and fixes without long waits. Important parts of this approach include regularly merging code changes and automatically delivering updates.                         |                      0.6 |  0.318182 | 0.11741   |                          5 |\n",
            "| The CAP theorem states that a distributed data store can only provide two of the three guarantees: Consistency, Availability, and Partition tolerance. Most modern distributed systems must choose which two properties to prioritize based on their specific needs.                                  | The CAP theorem explains that in systems where data is spread across multiple locations, it's only possible to have two out of three key qualities at the same time: keeping data consistent everywhere, ensuring the system is always available, and handling communication breakdowns between parts. Because of this, designers of such systems must decide which two qualities are most important for their needs. |                      0.3 |  0.35514  | 0.133948  |                          5 |\n",
            "\n",
            "--- Aggregate Metric Averages ---\n",
            "{\n",
            "    \"Average ROUGE-L\": 0.34125091564457716,\n",
            "    \"Average BLEU\": 0.08186966101825789,\n",
            "    \"Average Conciseness Score\": 0.53,\n",
            "    \"Average Clarity Score\": 5.0\n",
            "}\n",
            "\n",
            "--- Interpretation of Metrics ---\n",
            "**LLM Judge: Conciseness (Built-in `openevals`)**: A score (typically 1-5 or Pass/Fail) judged by an LLM based on a pre-defined prompt for conciseness. This is the recommended way to use pre-built criteria.\n",
            "**ROUGE-L & BLEU (Formula-Based)**: Scores between 0 and 1. They measure the word overlap between the generated summary and the reference summary. Higher scores mean the model's output is closer to the human-written ground truth.\n",
            "**LLM Judge: Clarity Score (Custom `openevals`)**: A custom 1-5 score, allowing for fine-grained, subjective quality assessment using a custom prompt, but leveraging the robust `create_llm_as_judge` framework.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "if run_results:\n",
        "    # Fetch the results from the completed run\n",
        "    df = run_results.to_pandas()\n",
        "\n",
        "    df['feedback.BLEU'] = df['feedback.BLEU'].astype(float)\n",
        "    df['feedback.ROUGE-L'] = df['feedback.ROUGE-L'].astype(float)\n",
        "\n",
        "    # Select relevant columns for display\n",
        "    display_cols = [\n",
        "        \"inputs.input\",\n",
        "        \"outputs.output\",\n",
        "        \"feedback.Conciseness\",\n",
        "        \"feedback.ROUGE-L\",\n",
        "        \"feedback.BLEU\",\n",
        "        \"feedback.Clarity_Score\",\n",
        "    ]\n",
        "\n",
        "    # Rename columns for clarity\n",
        "    df_display = df[display_cols].rename(columns={\n",
        "        \"inputs.input\": \"Input Text\",\n",
        "        \"outputs.output\": \"Generated Summary\",\n",
        "        \"feedback.Conciseness\": \"LLM Judge: Conciseness\",\n",
        "        \"feedback.Clarity_Score\": \"LLM Judge: Clarity Score\",\n",
        "        \"feedback.BLEU\":\"BLEU\",\"feedback.ROUGE-L\":\"ROUGE-L\"\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "    # Display the first few results\n",
        "    print(\"\\n--- Evaluation Results Summary (First 5 Samples) ---\")\n",
        "    pd.set_option('display.max_colwidth', 100)\n",
        "    print(df_display.head().to_markdown(index=False))\n",
        "\n",
        "    # Display aggregate metrics\n",
        "    print(\"\\n--- Aggregate Metric Averages ---\")\n",
        "\n",
        "    avg_metrics = {\n",
        "        \"Average ROUGE-L\": df['feedback.ROUGE-L'].mean(),\n",
        "        \"Average BLEU\": df['feedback.BLEU'].mean(),\n",
        "        # Conciseness and Clarity_Score are LLM-Judge outputs, which are typically strings or dictionaries.\n",
        "        # We'll assume the LLM-Judge outputs a score field for aggregation.\n",
        "        \"Average Conciseness Score\": df['feedback.Conciseness'].mean(),\n",
        "        \"Average Clarity Score\": df['feedback.Clarity_Score'].mean(),\n",
        "    }\n",
        "\n",
        "    print(json.dumps(avg_metrics, indent=4))\n",
        "\n",
        "    print(\"\\n--- Interpretation of Metrics ---\")\n",
        "    print(\"**LLM Judge: Conciseness (Built-in `openevals`)**: A score (typically 1-5 or Pass/Fail) judged by an LLM based on a pre-defined prompt for conciseness. This is the recommended way to use pre-built criteria.\")\n",
        "    print(\"**ROUGE-L & BLEU (Formula-Based)**: Scores between 0 and 1. They measure the word overlap between the generated summary and the reference summary. Higher scores mean the model's output is closer to the human-written ground truth.\")\n",
        "    print(\"**LLM Judge: Clarity Score (Custom `openevals`)**: A custom 1-5 score, allowing for fine-grained, subjective quality assessment using a custom prompt, but leveraging the robust `create_llm_as_judge` framework.\")\n",
        "else:\n",
        "    print(\"Analysis skipped due to failed experiment run.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCSwrAI2x7ox"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This exercise successfully demonstrated how to set up a multi-faceted evaluation pipeline in LangSmith:\n",
        "\n",
        "1.  **Dataset Management**: Creating and uploading a dataset to LangSmith.\n",
        "2.  **Experiment Execution**: Running an evaluation chain against the dataset using `client.evaluate()`.\n",
        "3.  **Diverse Evaluation**: Applying three types of evaluators simultaneously:\n",
        "    *   **Built-in**: `Conciseness` criteria.\n",
        "    *   **Formula-Based**: Custom code for **ROUGE-L** and **BLEU**.\n",
        "    *   **Custom LLM-as-a-Judge**: Custom criteria for **clarity**.\n",
        "\n",
        "This approach provides a holistic view of prompt performance, combining objective metrics with subjective, LLM-driven quality checks, which is essential for robust PromptOps.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxDEO4GXx7-Z"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09543b8735344521ba3bf951e4e9b5d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102ba5ffe3bf4ffc938d1c73177598fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "211183bcbc0a4e1682f0f656e1e02de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b831a7805c244efa120f080aaaa117c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69e66138df7242f0a7feb940bcb3fccb",
              "IPY_MODEL_e6aca9e14c1942e099d3e033e6901a62",
              "IPY_MODEL_99885e51e6814ed185db55f2e3f481ac"
            ],
            "layout": "IPY_MODEL_a16766da5bfc428888c999a4bc9f2943"
          }
        },
        "69e66138df7242f0a7feb940bcb3fccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09543b8735344521ba3bf951e4e9b5d3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aa79bd9d4cb44d92ae89a658f37112cd",
            "value": ""
          }
        },
        "851122b23025419ca2e0713dbf110fda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99885e51e6814ed185db55f2e3f481ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102ba5ffe3bf4ffc938d1c73177598fc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_211183bcbc0a4e1682f0f656e1e02de7",
            "value": "â€‡10/?â€‡[00:48&lt;00:00,â€‡â€‡4.70s/it]"
          }
        },
        "a16766da5bfc428888c999a4bc9f2943": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa79bd9d4cb44d92ae89a658f37112cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e001b669e4024833a23c6a38719d1e71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e6aca9e14c1942e099d3e033e6901a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e001b669e4024833a23c6a38719d1e71",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_851122b23025419ca2e0713dbf110fda",
            "value": 1
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
